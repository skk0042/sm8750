diff -ruN src_origin_with_susfs/fs/d_path.c src_modified_with_susfs/fs/d_path.c
--- src_origin_with_susfs/fs/d_path.c	2025-12-24 03:26:17.440091370 +0800
+++ src_modified_with_susfs/fs/d_path.c	2025-12-24 03:26:17.435093504 +0800
@@ -8,6 +8,9 @@
 #include <linux/prefetch.h>
 #include "mount.h"
 #include "internal.h"
+#ifdef CONFIG_HYMOFS
+#include "hymofs.h"
+#endif
 
 struct prepend_buffer {
 	char *buf;
@@ -235,6 +238,9 @@
 		return ERR_PTR(-EINVAL);
 	return extract_string(&b);
 }
+#ifdef CONFIG_HYMOFS
+EXPORT_SYMBOL(d_absolute_path);
+#endif
 
 static void get_fs_root_rcu(struct fs_struct *fs, struct path *root)
 {
@@ -291,7 +297,52 @@
 	prepend_path(path, &root, &b);
 	rcu_read_unlock();
 
+#ifdef CONFIG_HYMOFS
+    {
+        char *res = extract_string(&b);
+
+        /* Fast exit if no rules */
+        if (atomic_read(&hymo_atomiconfig) == 0)
+            return res;
+
+        /* Allow hymod to see real paths for management */
+        if (strcmp(current->comm, "hymod") == 0)
+            return res;
+
+        if (!IS_ERR(res)) {
+            /* Use stack buffer for lookup path to avoid allocation if possible */
+            char temp_path[256];
+            char *lookup_path = res;
+            int len = strlen(res);
+            bool allocated = false;
+            
+            /* We need to copy res because we might overwrite it when writing to buf */
+            if (len < sizeof(temp_path)) {
+                memcpy(temp_path, res, len + 1);
+                lookup_path = temp_path;
+            } else {
+                lookup_path = kmalloc(len + 1, GFP_KERNEL);
+                if (lookup_path) {
+                    memcpy(lookup_path, res, len + 1);
+                    allocated = true;
+                } else {
+                    lookup_path = res; /* Fallback, risky but rare */
+                }
+            }
+            
+            /* Write directly to buf */
+            if (hymofs_reverse_lookup(lookup_path, buf, buflen) > 0) {
+                if (allocated) kfree(lookup_path);
+                return buf;
+            }
+            
+            if (allocated) kfree(lookup_path);
+        }
+	    return res;
+    }
+#else
 	return extract_string(&b);
+#endif
 }
 EXPORT_SYMBOL(d_path);
 
diff -ruN src_origin_with_susfs/fs/hymofs.c src_modified_with_susfs/fs/hymofs.c
--- src_origin_with_susfs/fs/hymofs.c	1970-01-01 08:00:00.000000000 +0800
+++ src_modified_with_susfs/fs/hymofs.c	2025-12-28 11:28:07.657405028 +0800
@@ -0,0 +1,2211 @@
+#include <linux/string.h>
+#include <linux/mm.h>
+#include <linux/file.h>
+#include <linux/fdtable.h>
+#include <linux/fsnotify.h>
+#include <linux/module.h>
+#include <linux/tty.h>
+#include <linux/namei.h>
+#include <linux/backing-dev.h>
+#include <linux/capability.h>
+#include <linux/securebits.h>
+#include <linux/security.h>
+#include <linux/mount.h>
+#include <linux/fcntl.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/dcache.h>
+#include <linux/path.h>
+#include <linux/hashtable.h>
+#include <linux/init.h>
+#include <linux/time.h>
+#include <linux/dirent.h>
+#include <linux/miscdevice.h>
+#include <linux/cred.h>
+#include <linux/uidgid.h>
+#include <linux/vmalloc.h>
+#include <linux/atomic.h>
+#include <linux/spinlock.h>
+#include <linux/kernel.h>
+#include <linux/mnt_namespace.h>
+#include <linux/nsproxy.h>
+#include <linux/sched.h>
+#include <linux/fs_struct.h>
+#include <linux/sched/task.h>
+#include <linux/xattr.h>
+#include <linux/rcupdate.h>
+#include <linux/ioctl.h>
+#include "mount.h"
+
+#include "hymofs.h"
+#include <linux/hymo_magic.h>
+
+extern int (*hymo_dispatch_cmd_hook)(unsigned int cmd, void __user *arg);
+
+#ifdef CONFIG_HYMOFS_LSMBPS
+/* HymoFS SELinux Bypass Hook */
+extern int (*hymofs_selinux_bypass_file_open)(struct file *file);
+extern int (*hymofs_selinux_bypass_inode_permission)(struct inode *inode);
+extern int (*hymofs_selinux_bypass_setxattr)(struct dentry *dentry, const char *name);
+int hymofs_check_bypass(struct file *file);
+int hymofs_check_inode_bypass(struct inode *inode);
+int hymofs_check_setxattr_bypass(struct dentry *dentry, const char *name);
+#endif
+
+#ifdef CONFIG_HYMOFS_USE_KSU
+extern bool susfs_is_current_ksu_domain(void);
+#endif
+
+extern bool hymo_is_avc_log_spoofing_enabled;
+
+#ifdef CONFIG_HYMOFS
+
+/* HymoFS - Advanced Path Manipulation and Hiding */
+/* Increased hash bits to reduce collisions with large number of rules */
+#define HYMO_HASH_BITS 16
+
+struct hymo_linux_dirent {
+	unsigned long	d_ino;
+	unsigned long	d_off;
+	unsigned short	d_reclen;
+	char		d_name[];
+};
+
+struct hymo_entry {
+    char *src;
+    char *target;
+    unsigned char type;
+    struct hlist_node node;
+    struct hlist_node target_node;
+    struct rcu_head rcu;
+};
+struct hymo_hide_entry {
+    char *path;
+    struct hlist_node node;
+    struct rcu_head rcu;
+};
+
+struct hymo_inject_entry {
+    char *dir;
+    struct hlist_node node;
+    struct rcu_head rcu;
+};
+
+struct hymo_xattr_sb_entry {
+    struct super_block *sb;
+    struct hlist_node node;
+    struct rcu_head rcu;
+};
+
+struct hymo_merge_entry {
+    char *src;
+    char *target;
+    struct hlist_node node;
+    struct rcu_head rcu;
+};
+
+static DEFINE_HASHTABLE(hymo_paths, HYMO_HASH_BITS);
+static DEFINE_HASHTABLE(hymo_targets, HYMO_HASH_BITS);
+static DEFINE_HASHTABLE(hymo_hide_paths, HYMO_HASH_BITS);
+static DEFINE_HASHTABLE(hymo_inject_dirs, HYMO_HASH_BITS);
+static DEFINE_HASHTABLE(hymo_xattr_sbs, HYMO_HASH_BITS);
+static DEFINE_HASHTABLE(hymo_merge_dirs, HYMO_HASH_BITS);
+static DEFINE_SPINLOCK(hymo_lock);
+atomic_t hymo_atomiconfig = ATOMIC_INIT(0);
+EXPORT_SYMBOL(hymo_atomiconfig);
+
+static bool hymo_debug_enabled = false;
+module_param(hymo_debug_enabled, bool, 0644);
+MODULE_PARM_DESC(hymo_debug_enabled, "Enable debug logging");
+static bool hymo_stealth_enabled = true;
+
+static char hymo_mirror_path_buf[PATH_MAX] = HYMO_DEFAULT_MIRROR_PATH;
+static char hymo_mirror_name_buf[NAME_MAX] = HYMO_DEFAULT_MIRROR_NAME;
+static char *hymo_current_mirror_path = hymo_mirror_path_buf;
+static char *hymo_current_mirror_name = hymo_mirror_name_buf;
+
+#define hymo_log(fmt, ...) do { \
+    if (hymo_debug_enabled) \
+        printk(KERN_INFO "hymofs: " fmt, ##__VA_ARGS__); \
+} while(0)
+
+/* RCU callback functions for deferred free */
+static void hymo_entry_free_rcu(struct rcu_head *head)
+{
+    struct hymo_entry *e = container_of(head, struct hymo_entry, rcu);
+    kfree(e->src);
+    kfree(e->target);
+    kfree(e);
+}
+
+static void hymo_hide_entry_free_rcu(struct rcu_head *head)
+{
+    struct hymo_hide_entry *e = container_of(head, struct hymo_hide_entry, rcu);
+    kfree(e->path);
+    kfree(e);
+}
+
+static void hymo_inject_entry_free_rcu(struct rcu_head *head)
+{
+    struct hymo_inject_entry *e = container_of(head, struct hymo_inject_entry, rcu);
+    kfree(e->dir);
+    kfree(e);
+}
+
+static void hymo_xattr_sb_entry_free_rcu(struct rcu_head *head)
+{
+    struct hymo_xattr_sb_entry *e = container_of(head, struct hymo_xattr_sb_entry, rcu);
+    kfree(e);
+}
+
+static void hymo_merge_entry_free_rcu(struct rcu_head *head)
+{
+    struct hymo_merge_entry *e = container_of(head, struct hymo_merge_entry, rcu);
+    kfree(e->src);
+    kfree(e->target);
+    kfree(e);
+}
+
+/*
+ * Inode-based hide marking for O(1) lookup performance
+ * Uses inode->i_mapping->flags bit 40 to mark hidden inodes
+ */
+static inline void hymofs_mark_inode_hidden(struct inode *inode)
+{
+    if (inode && inode->i_mapping) {
+        set_bit(AS_FLAGS_HYMO_HIDE, &inode->i_mapping->flags);
+    }
+}
+
+static inline void hymofs_unmark_inode_hidden(struct inode *inode)
+{
+    if (inode && inode->i_mapping) {
+        clear_bit(AS_FLAGS_HYMO_HIDE, &inode->i_mapping->flags);
+    }
+}
+
+/* Fast O(1) check if inode is marked hidden */
+bool __hymofs_is_inode_hidden(struct inode *inode)
+{
+    /* Fast path checks are in the inline wrapper */
+    return test_bit(AS_FLAGS_HYMO_HIDE, &inode->i_mapping->flags);
+}
+EXPORT_SYMBOL(__hymofs_is_inode_hidden);
+
+static void hymo_cleanup_locked(void) {
+    struct hymo_entry *entry;
+    struct hymo_hide_entry *hide_entry;
+    struct hymo_inject_entry *inject_entry;
+    struct hymo_xattr_sb_entry *sb_entry;
+    struct hymo_merge_entry *merge_entry;
+    struct hlist_node *tmp;
+    int bkt;
+    
+    /* Mark entries for RCU deletion - actual freeing happens after grace period */
+    hash_for_each_safe(hymo_paths, bkt, tmp, entry, node) {
+        hlist_del_rcu(&entry->node);
+        hlist_del_rcu(&entry->target_node);
+        call_rcu(&entry->rcu, hymo_entry_free_rcu);
+    }
+    hash_for_each_safe(hymo_hide_paths, bkt, tmp, hide_entry, node) {
+        hlist_del_rcu(&hide_entry->node);
+        call_rcu(&hide_entry->rcu, hymo_hide_entry_free_rcu);
+    }
+    hash_for_each_safe(hymo_inject_dirs, bkt, tmp, inject_entry, node) {
+        hlist_del_rcu(&inject_entry->node);
+        call_rcu(&inject_entry->rcu, hymo_inject_entry_free_rcu);
+    }
+    hash_for_each_safe(hymo_xattr_sbs, bkt, tmp, sb_entry, node) {
+        hlist_del_rcu(&sb_entry->node);
+        call_rcu(&sb_entry->rcu, hymo_xattr_sb_entry_free_rcu);
+    }
+    hash_for_each_safe(hymo_merge_dirs, bkt, tmp, merge_entry, node) {
+        hlist_del_rcu(&merge_entry->node);
+        call_rcu(&merge_entry->rcu, hymo_merge_entry_free_rcu);
+    }
+    /* Note: rcu_barrier() is called after releasing the lock */
+}
+
+static void hymofs_add_inject_rule(char *dir)
+{
+    struct hymo_inject_entry *inject_entry;
+    u32 hash;
+    bool found = false;
+
+    if (!dir) return;
+
+    hash = full_name_hash(NULL, dir, strlen(dir));
+    /* Note: This function is called within spin_lock context by callers */
+    hlist_for_each_entry(inject_entry, &hymo_inject_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+        if (strcmp(inject_entry->dir, dir) == 0) {
+            found = true;
+            break;
+        }
+    }
+    if (!found) {
+        inject_entry = kmalloc(sizeof(*inject_entry), GFP_ATOMIC);
+        if (inject_entry) {
+            inject_entry->dir = dir; // Transfer ownership
+            hlist_add_head_rcu(&inject_entry->node, &hymo_inject_dirs[hash_min(hash, HYMO_HASH_BITS)]);
+            hymo_log("auto-inject parent: %s\n", dir);
+        } else {
+            kfree(dir);
+        }
+    } else {
+        kfree(dir);
+    }
+}
+
+static void hymofs_reorder_mnt_id(void)
+{
+    struct mnt_namespace *ns = current->nsproxy->mnt_ns;
+    struct mount *m;
+    int id = 1;
+    bool is_hymo_mount;
+    
+    // Try to find the starting ID from the first mount
+    if (ns && !list_empty(&ns->list)) {
+        struct mount *first = list_first_entry(&ns->list, struct mount, mnt_list);
+        if (first->mnt_id < 500000) id = first->mnt_id;
+    }
+
+    if (!ns) return;
+
+    list_for_each_entry(m, &ns->list, mnt_list) {
+        is_hymo_mount = false;
+        
+        if (m->mnt_devname && (
+            strcmp(m->mnt_devname, hymo_current_mirror_path) == 0 || 
+            strcmp(m->mnt_devname, hymo_current_mirror_name) == 0
+        )) {
+            is_hymo_mount = true;
+        }
+
+        if (is_hymo_mount && hymo_stealth_enabled) {
+            // Hide it by assigning a high ID (susfs compatible)
+            // 500000 is DEFAULT_KSU_MNT_ID
+            if (m->mnt_id < 500000) {
+#ifdef CONFIG_KSU_SUSFS
+                WRITE_ONCE(m->mnt.susfs_mnt_id_backup, m->mnt_id);
+#endif
+                WRITE_ONCE(m->mnt_id, 500000 + (id % 1000)); // Use a range
+            }
+        } else {
+            // Skip if already hidden (by susfs or us)
+            if (m->mnt_id >= 500000) continue;
+            
+#ifdef CONFIG_KSU_SUSFS
+            WRITE_ONCE(m->mnt.susfs_mnt_id_backup, m->mnt_id);
+#endif
+            WRITE_ONCE(m->mnt_id, id++);
+        }
+    }
+}
+
+static void hymofs_spoof_mounts(void)
+{
+    struct mnt_namespace *ns = current->nsproxy->mnt_ns;
+    struct mount *m;
+    char *system_devname = NULL;
+    struct path sys_path;
+
+    if (!ns) return;
+    if (!hymo_stealth_enabled) return;
+
+    // Resolve /system to get its device name
+    if (kern_path("/system", LOOKUP_FOLLOW, &sys_path) == 0) {
+        struct mount *sys_mnt = real_mount(sys_path.mnt);
+        if (sys_mnt && sys_mnt->mnt_devname) {
+            system_devname = kstrdup(sys_mnt->mnt_devname, GFP_KERNEL);
+        }
+        path_put(&sys_path);
+    }
+    
+    // Fallback to / if /system is not separate
+    if (!system_devname) {
+        if (kern_path("/", LOOKUP_FOLLOW, &sys_path) == 0) {
+            struct mount *sys_mnt = real_mount(sys_path.mnt);
+            if (sys_mnt && sys_mnt->mnt_devname) {
+                system_devname = kstrdup(sys_mnt->mnt_devname, GFP_KERNEL);
+            }
+            path_put(&sys_path);
+        }
+    }
+
+    if (!system_devname) return;
+
+    list_for_each_entry(m, &ns->list, mnt_list) {
+        if (m->mnt_devname && (
+            strcmp(m->mnt_devname, hymo_current_mirror_path) == 0 || 
+            strcmp(m->mnt_devname, hymo_current_mirror_name) == 0
+        )) {
+            // Spoof devname
+            const char *old_name = m->mnt_devname;
+            m->mnt_devname = kstrdup(system_devname, GFP_KERNEL);
+            if (m->mnt_devname) {
+                kfree_const(old_name);
+            } else {
+                m->mnt_devname = old_name; // Restore if alloc failed
+            }
+        }
+    }
+    kfree(system_devname);
+}
+
+static int hymo_dispatch_cmd(unsigned int cmd, void __user *arg) {
+    struct hymo_syscall_arg req;
+    struct hymo_entry *entry;
+    struct hymo_hide_entry *hide_entry;
+    struct hymo_inject_entry *inject_entry;
+    char *src = NULL, *target = NULL;
+    u32 hash;
+    unsigned long flags;
+    bool found = false;
+    int ret = 0;
+
+    if (cmd == HYMO_CMD_CLEAR_ALL) {
+        spin_lock(&hymo_lock);
+        hymo_cleanup_locked();
+        strscpy(hymo_mirror_path_buf, HYMO_DEFAULT_MIRROR_PATH, PATH_MAX);
+        strscpy(hymo_mirror_name_buf, HYMO_DEFAULT_MIRROR_NAME, NAME_MAX);
+        hymo_current_mirror_path = hymo_mirror_path_buf;
+        hymo_current_mirror_name = hymo_mirror_name_buf;
+        atomic_inc(&hymo_atomiconfig);
+        spin_unlock(&hymo_lock);
+        /* Wait for RCU grace period after releasing lock */
+        rcu_barrier();
+        return 0;
+    }
+    
+    if (cmd == HYMO_CMD_GET_VERSION) {
+        return HYMO_PROTOCOL_VERSION;
+    }
+
+    if (cmd == HYMO_CMD_SET_DEBUG) {
+        int val;
+        if (copy_from_user(&val, arg, sizeof(val))) return -EFAULT;
+        hymo_debug_enabled = !!val;
+        hymo_log("debug mode %s\n", hymo_debug_enabled ? "enabled" : "disabled");
+        return 0;
+    }
+
+    if (cmd == HYMO_CMD_REORDER_MNT_ID) {
+        hymofs_spoof_mounts();
+        hymofs_reorder_mnt_id();
+        return 0;
+    }
+
+    if (cmd == HYMO_CMD_SET_STEALTH) {
+        int val;
+        if (copy_from_user(&val, arg, sizeof(val))) return -EFAULT;
+        hymo_stealth_enabled = !!val;
+        hymo_log("stealth mode %s\n", hymo_stealth_enabled ? "enabled" : "disabled");
+        if (hymo_stealth_enabled) {
+            hymofs_spoof_mounts();
+            hymofs_reorder_mnt_id();
+        }
+        return 0;
+    }
+
+    if (copy_from_user(&req, arg, sizeof(req))) return -EFAULT;
+
+    if (cmd == HYMO_CMD_SET_MIRROR_PATH) {
+        char *new_path = NULL;
+        char *new_name = NULL;
+        
+        if (req.src) {
+            new_path = strndup_user(req.src, PATH_MAX);
+            if (IS_ERR(new_path)) return PTR_ERR(new_path);
+        } else {
+            return -EINVAL;
+        }
+
+        hymo_log("setting mirror path to: %s\n", new_path);
+
+        /* Strip trailing slash if present */
+        size_t len = strlen(new_path);
+        if (len > 1 && new_path[len - 1] == '/') {
+            new_path[len - 1] = '\0';
+        }
+
+        char *slash = strrchr(new_path, '/');
+        if (slash) {
+            new_name = kstrdup(slash + 1, GFP_KERNEL);
+        } else {
+            new_name = kstrdup(new_path, GFP_KERNEL);
+        }
+
+        if (!new_name) {
+            kfree(new_path);
+            return -ENOMEM;
+        }
+
+        spin_lock(&hymo_lock);
+        strscpy(hymo_mirror_path_buf, new_path, PATH_MAX);
+        strscpy(hymo_mirror_name_buf, new_name, NAME_MAX);
+        hymo_current_mirror_path = hymo_mirror_path_buf;
+        hymo_current_mirror_name = hymo_mirror_name_buf;
+        spin_unlock(&hymo_lock);
+
+        kfree(new_path);
+        kfree(new_name);
+        return 0;
+    }
+
+    if (req.src) {
+        src = strndup_user(req.src, PAGE_SIZE);
+        if (IS_ERR(src)) return PTR_ERR(src);
+    }
+    if (req.target) {
+        target = strndup_user(req.target, PAGE_SIZE);
+        if (IS_ERR(target)) {
+            kfree(src);
+            return PTR_ERR(target);
+        }
+    }
+
+    switch (cmd) {
+        case HYMO_CMD_ADD_MERGE_RULE: {
+            struct hymo_merge_entry *merge_entry;
+            if (!src || !target) { ret = -EINVAL; break; }
+            
+            hymo_log("add merge rule: src=%s, target=%s\n", src, target);
+            
+            hash = full_name_hash(NULL, src, strlen(src));
+            spin_lock(&hymo_lock);
+            
+            // Check if exists
+            hlist_for_each_entry(merge_entry, &hymo_merge_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+                if (strcmp(merge_entry->src, src) == 0 && strcmp(merge_entry->target, target) == 0) {
+                    found = true;
+                    break;
+                }
+            }
+            
+            if (!found) {
+                merge_entry = kmalloc(sizeof(*merge_entry), GFP_ATOMIC);
+                if (merge_entry) {
+                    merge_entry->src = src;
+                    merge_entry->target = target;
+                    hlist_add_head_rcu(&merge_entry->node, &hymo_merge_dirs[hash_min(hash, HYMO_HASH_BITS)]);
+                    
+                    /* Add inject rule if not present */
+                    {
+                        struct hymo_inject_entry *inj;
+                        bool inj_found = false;
+                        hlist_for_each_entry(inj, &hymo_inject_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+                            if (strcmp(inj->dir, src) == 0) {
+                                inj_found = true;
+                                break;
+                            }
+                        }
+                        if (!inj_found) {
+                            inj = kmalloc(sizeof(*inj), GFP_ATOMIC);
+                            if (inj) {
+                                inj->dir = kstrdup(src, GFP_ATOMIC);
+                                if (inj->dir) hlist_add_head_rcu(&inj->node, &hymo_inject_dirs[hash_min(hash, HYMO_HASH_BITS)]);
+                                else kfree(inj);
+                            }
+                        }
+                    }
+                    
+                    src = NULL; // Ownership transferred
+                    target = NULL;
+                    hymofs_add_inject_rule(kstrdup(merge_entry->src, GFP_ATOMIC)); // Also mark for injection
+                } else {
+                    ret = -ENOMEM;
+                }
+            } else {
+                ret = -EEXIST;
+            }
+            atomic_inc(&hymo_atomiconfig);
+            spin_unlock(&hymo_lock);
+            break;
+        }
+
+        case HYMO_CMD_ADD_RULE: {
+            char *parent_dir = NULL;
+            char *resolved_src = NULL;
+            struct path path;
+            struct inode *src_inode = NULL;
+            struct inode *parent_inode = NULL;
+            char *tmp_buf = kmalloc(PATH_MAX, GFP_KERNEL);
+            
+            if (!src || !target) { 
+                kfree(tmp_buf);
+                ret = -EINVAL; 
+                break; 
+            }
+            if (!tmp_buf) { ret = -ENOMEM; break; }
+
+            hymo_log("add rule: src=%s, target=%s, type=%d\n", src, target, req.type);
+            
+            // 1. Try to resolve full path (if file exists)
+            if (kern_path(src, LOOKUP_FOLLOW, &path) == 0) {
+                char *res = d_path(&path, tmp_buf, PATH_MAX);
+                if (!IS_ERR(res)) {
+                    resolved_src = kstrdup(res, GFP_KERNEL);
+                    
+                    /* Always extract parent directory for injection, even if file exists */
+                    {
+                        char *last_slash = strrchr(res, '/');
+                        if (last_slash) {
+                            if (last_slash == res) {
+                                parent_dir = kstrdup("/", GFP_KERNEL);
+                            } else {
+                                size_t len = last_slash - res;
+                                parent_dir = kmalloc(len + 1, GFP_KERNEL);
+                                if (parent_dir) {
+                                    memcpy(parent_dir, res, len);
+                                    parent_dir[len] = '\0';
+                                }
+                            }
+                        }
+                    }
+                }
+                /* Get inode reference for marking (hide source in filldir) */
+                if (d_inode(path.dentry)) {
+                    src_inode = d_inode(path.dentry);
+                    ihold(src_inode);
+                }
+                /* Also get parent directory inode */
+                if (path.dentry->d_parent && d_inode(path.dentry->d_parent)) {
+                    parent_inode = d_inode(path.dentry->d_parent);
+                    ihold(parent_inode);
+                }
+                path_put(&path);
+            } else {
+                // 2. Path does not exist, try to resolve parent
+                char *last_slash = strrchr(src, '/');
+                if (last_slash && last_slash != src) {
+                    size_t len = last_slash - src;
+                    char *p_str = kmalloc(len + 1, GFP_KERNEL);
+                    if (p_str) {
+                        memcpy(p_str, src, len);
+                        p_str[len] = '\0';
+                        
+                        if (kern_path(p_str, LOOKUP_FOLLOW, &path) == 0) {
+                            char *res = d_path(&path, tmp_buf, PATH_MAX);
+                            if (!IS_ERR(res)) {
+                                // Reconstruct src = parent_resolved + / + filename
+                                size_t res_len = strlen(res);
+                                size_t name_len = strlen(last_slash);
+                                resolved_src = kmalloc(res_len + name_len + 1, GFP_KERNEL);
+                                if (resolved_src) {
+                                    strcpy(resolved_src, res);
+                                    strcat(resolved_src, last_slash);
+                                }
+                                // We need to inject this parent
+                                parent_dir = kstrdup(res, GFP_KERNEL);
+                            }
+                            path_put(&path);
+                        }
+                        kfree(p_str);
+                    }
+                }
+            }
+            
+            kfree(tmp_buf);
+
+            if (resolved_src) {
+                kfree(src);
+                src = resolved_src;
+            }
+
+            hash = full_name_hash(NULL, src, strlen(src));
+            spin_lock(&hymo_lock);
+
+            {
+                hlist_for_each_entry(entry, &hymo_paths[hash_min(hash, HYMO_HASH_BITS)], node) {
+                    if (strcmp(entry->src, src) == 0) {
+                        /* Update existing entry - need RCU-safe update */
+                        char *old_target = entry->target;
+                        char *new_target = kstrdup(target, GFP_ATOMIC);
+                        if (new_target) {
+                            hlist_del_rcu(&entry->target_node);
+                            rcu_assign_pointer(entry->target, new_target);
+                            entry->type = req.type;
+                            hlist_add_head_rcu(&entry->target_node, &hymo_targets[hash_min(full_name_hash(NULL, new_target, strlen(new_target)), HYMO_HASH_BITS)]);
+                            /* Free old target after grace period - use kfree_rcu if available, else synchronize */
+                            kfree(old_target);
+                        }
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    entry = kmalloc(sizeof(*entry), GFP_ATOMIC);
+                    if (entry) {
+                        entry->src = kstrdup(src, GFP_ATOMIC);
+                        entry->target = kstrdup(target, GFP_ATOMIC);
+                        entry->type = req.type;
+                        if (entry->src && entry->target) {
+                            hlist_add_head_rcu(&entry->node, &hymo_paths[hash_min(hash, HYMO_HASH_BITS)]);
+                            hlist_add_head_rcu(&entry->target_node, &hymo_targets[hash_min(full_name_hash(NULL, entry->target, strlen(entry->target)), HYMO_HASH_BITS)]);
+                        } else {
+                            kfree(entry->src);
+                            kfree(entry->target);
+                            kfree(entry);
+                        }
+                    }
+                }
+            }
+
+            // Add inject rule if needed
+            if (parent_dir) {
+                hymofs_add_inject_rule(parent_dir);
+            }
+
+            /* Mark source inode as hidden (O(1) fast path for filldir) */
+            if (src_inode) {
+                hymofs_mark_inode_hidden(src_inode);
+                iput(src_inode);
+            }
+
+            /* Mark parent directory as "has hidden entries" for fast filldir skip */
+            if (parent_inode) {
+                if (parent_inode->i_mapping) {
+                    set_bit(AS_FLAGS_HYMO_DIR_HAS_HIDDEN, &parent_inode->i_mapping->flags);
+                }
+                iput(parent_inode);
+            }
+
+            atomic_inc(&hymo_atomiconfig);
+            spin_unlock(&hymo_lock);
+            break;
+        }
+
+        case HYMO_CMD_HIDE_RULE: {
+            char *resolved_src = NULL;
+            struct path path;
+            struct inode *target_inode = NULL;
+            struct inode *parent_inode = NULL;
+            char *tmp_buf = kmalloc(PATH_MAX, GFP_KERNEL);
+
+            if (!src) { 
+                kfree(tmp_buf);
+                ret = -EINVAL; 
+                break; 
+            }
+            if (!tmp_buf) { ret = -ENOMEM; break; }
+
+            hymo_log("hide rule: src=%s\n", src);
+
+            if (kern_path(src, LOOKUP_FOLLOW, &path) == 0) {
+                char *res = d_path(&path, tmp_buf, PATH_MAX);
+                if (!IS_ERR(res)) {
+                    resolved_src = kstrdup(res, GFP_KERNEL);
+                }
+                /* Get inode reference for marking */
+                if (d_inode(path.dentry)) {
+                    target_inode = d_inode(path.dentry);
+                    ihold(target_inode);  /* Hold reference */
+                }
+                /* Also get parent directory inode */
+                if (path.dentry->d_parent && d_inode(path.dentry->d_parent)) {
+                    parent_inode = d_inode(path.dentry->d_parent);
+                    ihold(parent_inode);
+                }
+                path_put(&path);
+            }
+            kfree(tmp_buf);
+
+            if (resolved_src) {
+                kfree(src);
+                src = resolved_src;
+            }
+
+            /* Mark inode as hidden (O(1) fast path) */
+            if (target_inode) {
+                hymofs_mark_inode_hidden(target_inode);
+                iput(target_inode);  /* Release reference */
+            }
+
+            /* Mark parent directory as "has hidden entries" for fast filldir skip */
+            if (parent_inode) {
+                if (parent_inode->i_mapping) {
+                    set_bit(AS_FLAGS_HYMO_DIR_HAS_HIDDEN, &parent_inode->i_mapping->flags);
+                }
+                iput(parent_inode);
+            }
+
+            /* Also add to hash table for path-based fallback lookup */
+            hash = full_name_hash(NULL, src, strlen(src));
+            spin_lock(&hymo_lock);
+            hlist_for_each_entry(hide_entry, &hymo_hide_paths[hash_min(hash, HYMO_HASH_BITS)], node) {
+                if (strcmp(hide_entry->path, src) == 0) {
+                    found = true;
+                    break;
+                }
+            }
+            if (!found) {
+                hide_entry = kmalloc(sizeof(*hide_entry), GFP_ATOMIC);
+                if (hide_entry) {
+                    hide_entry->path = kstrdup(src, GFP_ATOMIC);
+                    if (hide_entry->path)
+                        hlist_add_head_rcu(&hide_entry->node, &hymo_hide_paths[hash_min(hash, HYMO_HASH_BITS)]);
+                    else
+                        kfree(hide_entry);
+                }
+            }
+            atomic_inc(&hymo_atomiconfig);
+            spin_unlock(&hymo_lock);
+            break;
+        }
+
+        case HYMO_CMD_HIDE_OVERLAY_XATTRS: {
+            struct path path;
+            struct hymo_xattr_sb_entry *sb_entry;
+            bool found = false;
+            
+            if (!src) { ret = -EINVAL; break; }
+            
+            if (kern_path(src, LOOKUP_FOLLOW, &path) == 0) {
+                struct super_block *sb = path.dentry->d_sb;
+                
+                spin_lock(&hymo_lock);
+                hlist_for_each_entry(sb_entry, &hymo_xattr_sbs[hash_min((unsigned long)sb, HYMO_HASH_BITS)], node) {
+                    if (sb_entry->sb == sb) {
+                        found = true;
+                        break;
+                    }
+                }
+                if (!found) {
+                    sb_entry = kmalloc(sizeof(*sb_entry), GFP_ATOMIC);
+                    if (sb_entry) {
+                        sb_entry->sb = sb;
+                        hlist_add_head_rcu(&sb_entry->node, &hymo_xattr_sbs[hash_min((unsigned long)sb, HYMO_HASH_BITS)]);
+                        hymo_log("hide xattrs for sb %p (path: %s)\n", sb, src);
+                    }
+                }
+                atomic_inc(&hymo_atomiconfig);
+                spin_unlock(&hymo_lock);
+                path_put(&path);
+            } else {
+                ret = -ENOENT;
+            }
+            break;
+        }
+
+        case HYMO_CMD_DEL_RULE:
+            if (!src) { ret = -EINVAL; break; }
+            hymo_log("del rule: src=%s\n", src);
+            hash = full_name_hash(NULL, src, strlen(src));
+            spin_lock(&hymo_lock);
+            
+            hlist_for_each_entry(entry, &hymo_paths[hash_min(hash, HYMO_HASH_BITS)], node) {
+                if (strcmp(entry->src, src) == 0) {
+                    hlist_del_rcu(&entry->node);
+                    hlist_del_rcu(&entry->target_node);
+                    call_rcu(&entry->rcu, hymo_entry_free_rcu);
+                    goto out_delete;
+                }
+            }
+            hlist_for_each_entry(hide_entry, &hymo_hide_paths[hash_min(hash, HYMO_HASH_BITS)], node) {
+                if (strcmp(hide_entry->path, src) == 0) {
+                    hlist_del_rcu(&hide_entry->node);
+                    call_rcu(&hide_entry->rcu, hymo_hide_entry_free_rcu);
+                    goto out_delete;
+                }
+            }
+            hlist_for_each_entry(inject_entry, &hymo_inject_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+                if (strcmp(inject_entry->dir, src) == 0) {
+                    hlist_del_rcu(&inject_entry->node);
+                    call_rcu(&inject_entry->rcu, hymo_inject_entry_free_rcu);
+                    goto out_delete;
+                }
+            }
+            // Note: We don't support deleting xattr SB rules by path easily here
+            // because we store SBs, not paths. Use CLEAR_ALL to reset.
+    out_delete:
+            atomic_inc(&hymo_atomiconfig);
+            spin_unlock(&hymo_lock);
+            break;
+
+        case HYMO_CMD_LIST_RULES: {
+            struct hymo_syscall_list_arg list_arg;
+            char *kbuf;
+            size_t buf_size;
+            size_t written = 0;
+            int bkt;
+            struct hymo_xattr_sb_entry *sb_entry;
+            struct hymo_merge_entry *merge_entry;
+
+            if (copy_from_user(&list_arg, (void __user *)arg, sizeof(list_arg))) {
+                ret = -EFAULT;
+                break;
+            }
+
+            buf_size = list_arg.size;
+            if (buf_size > 128 * 1024) buf_size = 128 * 1024; // Limit max buffer
+            
+            kbuf = kzalloc(buf_size, GFP_KERNEL);
+            if (!kbuf) {
+                ret = -ENOMEM;
+                break;
+            }
+
+            rcu_read_lock();
+            
+            // Header
+            written += scnprintf(kbuf + written, buf_size - written, "HymoFS Protocol: %d\n", HYMO_PROTOCOL_VERSION);
+            written += scnprintf(kbuf + written, buf_size - written, "HymoFS Atomiconfig Version: %d\n", atomic_read(&hymo_atomiconfig));
+
+            hash_for_each_rcu(hymo_paths, bkt, entry, node) {
+                if (written >= buf_size) break;
+                written += scnprintf(kbuf + written, buf_size - written, "add %s %s %d\n", entry->src, entry->target, entry->type);
+            }
+            hash_for_each_rcu(hymo_hide_paths, bkt, hide_entry, node) {
+                if (written >= buf_size) break;
+                written += scnprintf(kbuf + written, buf_size - written, "hide %s\n", hide_entry->path);
+            }
+            hash_for_each_rcu(hymo_inject_dirs, bkt, inject_entry, node) {
+                if (written >= buf_size) break;
+                written += scnprintf(kbuf + written, buf_size - written, "inject %s\n", inject_entry->dir);
+            }
+            hash_for_each_rcu(hymo_merge_dirs, bkt, merge_entry, node) {
+                if (written >= buf_size) break;
+                written += scnprintf(kbuf + written, buf_size - written, "merge %s %s\n", merge_entry->src, merge_entry->target);
+            }
+            hash_for_each_rcu(hymo_xattr_sbs, bkt, sb_entry, node) {
+                if (written >= buf_size) break;
+                written += scnprintf(kbuf + written, buf_size - written, "hide_xattr_sb %p\n", sb_entry->sb);
+            }
+            rcu_read_unlock();
+
+            if (copy_to_user(list_arg.buf, kbuf, written)) {
+                ret = -EFAULT;
+            } else {
+                // Update size to actual written bytes
+                list_arg.size = written;
+                if (copy_to_user((void __user *)arg, &list_arg, sizeof(list_arg))) {
+                    ret = -EFAULT;
+                }
+            }
+            
+            kfree(kbuf);
+            break;
+        }
+
+        case HYMO_CMD_REORDER_MNT_ID:
+            hymo_log("reordering mount IDs\n");
+            hymofs_reorder_mnt_id();
+            break;
+
+        case HYMO_CMD_SET_AVC_LOG_SPOOFING:
+            if (req.type) {
+                hymo_is_avc_log_spoofing_enabled = true;
+                hymo_log("AVC log spoofing enabled\n");
+            } else {
+                hymo_is_avc_log_spoofing_enabled = false;
+                hymo_log("AVC log spoofing disabled\n");
+            }
+            break;
+
+        default:
+            ret = -EINVAL;
+            break;
+    }
+
+    kfree(src);
+    kfree(target);
+    return ret;
+}
+
+/* ================= fd-based communication (miscdevice) ================= */
+
+static int hymo_ioctl_cmd_to_syscall_cmd(unsigned int ioctl_cmd)
+{
+    switch (ioctl_cmd) {
+    case HYMO_IOC_ADD_RULE:           return HYMO_CMD_ADD_RULE;
+    case HYMO_IOC_DEL_RULE:           return HYMO_CMD_DEL_RULE;
+    case HYMO_IOC_HIDE_RULE:          return HYMO_CMD_HIDE_RULE;
+    case HYMO_IOC_CLEAR_ALL:          return HYMO_CMD_CLEAR_ALL;
+    case HYMO_IOC_GET_VERSION:        return HYMO_CMD_GET_VERSION;
+    case HYMO_IOC_LIST_RULES:         return HYMO_CMD_LIST_RULES;
+    case HYMO_IOC_SET_DEBUG:          return HYMO_CMD_SET_DEBUG;
+    case HYMO_IOC_REORDER_MNT_ID:     return HYMO_CMD_REORDER_MNT_ID;
+    case HYMO_IOC_SET_STEALTH:        return HYMO_CMD_SET_STEALTH;
+    case HYMO_IOC_HIDE_OVERLAY_XATTRS: return HYMO_CMD_HIDE_OVERLAY_XATTRS;
+    case HYMO_IOC_ADD_MERGE_RULE:     return HYMO_CMD_ADD_MERGE_RULE;
+    case HYMO_IOC_SET_AVC_LOG_SPOOFING: return HYMO_CMD_SET_AVC_LOG_SPOOFING;
+    case HYMO_IOC_SET_MIRROR_PATH:    return HYMO_CMD_SET_MIRROR_PATH;
+    default:                          return -1;
+    }
+}
+
+static int hymo_dev_open(struct inode *inode, struct file *file)
+{
+    /* Only allow root to open */
+    if (!uid_eq(current_uid(), GLOBAL_ROOT_UID)) {
+        return -EPERM;
+    }
+    return 0;
+}
+
+static int hymo_dev_release(struct inode *inode, struct file *file)
+{
+    return 0;
+}
+
+static long hymo_dev_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+    int syscall_cmd;
+    int ret;
+
+    /* Handle GET_VERSION specially - return version directly */
+    if (cmd == HYMO_IOC_GET_VERSION) {
+        int version = HYMO_PROTOCOL_VERSION;
+        if (copy_to_user((void __user *)arg, &version, sizeof(version)))
+            return -EFAULT;
+        return 0;
+    }
+
+    /* Convert ioctl cmd to syscall cmd */
+    syscall_cmd = hymo_ioctl_cmd_to_syscall_cmd(cmd);
+    if (syscall_cmd < 0) {
+        return -EINVAL;
+    }
+
+    /* Reuse existing dispatch logic */
+    ret = hymo_dispatch_cmd(syscall_cmd, (void __user *)arg);
+    return ret;
+}
+
+static const struct file_operations hymo_dev_fops = {
+    .owner          = THIS_MODULE,
+    .open           = hymo_dev_open,
+    .release        = hymo_dev_release,
+    .unlocked_ioctl = hymo_dev_ioctl,
+    .compat_ioctl   = hymo_dev_ioctl,
+};
+
+static struct miscdevice hymo_misc_dev = {
+    .minor = MISC_DYNAMIC_MINOR,
+    .name  = HYMO_DEVICE_NAME,
+    .fops  = &hymo_dev_fops,
+    .mode  = 0600, /* Only root can access */
+};
+
+static bool hymo_dev_registered = false;
+
+/* ================= End of fd-based communication ================= */
+
+static int __init hymofs_init(void)
+{
+    int ret;
+
+    spin_lock_init(&hymo_lock);
+    hash_init(hymo_paths);
+    hash_init(hymo_targets);
+    hash_init(hymo_hide_paths);
+    hash_init(hymo_inject_dirs);
+    hash_init(hymo_xattr_sbs);
+    
+    /* Register syscall hook (legacy mode) */
+    if (hymo_dispatch_cmd_hook) {
+        pr_err("HymoFS: hook already set?\n");
+    } else {
+        hymo_dispatch_cmd_hook = hymo_dispatch_cmd;
+    }
+
+    /* Register miscdevice (fd-based mode) */
+    ret = misc_register(&hymo_misc_dev);
+    if (ret) {
+        pr_warn("HymoFS: Failed to register misc device (ret=%d), fd-based mode unavailable\n", ret);
+    } else {
+        hymo_dev_registered = true;
+        pr_info("HymoFS: Registered /dev/%s for fd-based communication\n", HYMO_DEVICE_NAME);
+    }
+    
+    /* Register SELinux Bypass */
+#ifdef CONFIG_HYMOFS_LSMBPS
+    if (hymofs_selinux_bypass_file_open == NULL) {
+        hymofs_selinux_bypass_file_open = hymofs_check_bypass;
+    }
+    if (hymofs_selinux_bypass_inode_permission == NULL) {
+        hymofs_selinux_bypass_inode_permission = hymofs_check_inode_bypass;
+    }
+    if (hymofs_selinux_bypass_setxattr == NULL) {
+        hymofs_selinux_bypass_setxattr = hymofs_check_setxattr_bypass;
+    }
+#endif /* CONFIG_HYMOFS_LSMBPS */
+
+    pr_info("HymoFS: initialized (Syscall + FD Mode)\n");
+    return 0;
+}
+fs_initcall(hymofs_init);
+
+/* Returns kstrdup'd target if found, NULL otherwise. Caller must kfree. */
+char *__hymofs_resolve_target(const char *pathname)
+{
+    struct hymo_entry *entry;
+    struct hymo_merge_entry *merge_entry;
+    u32 hash;
+    char *target = NULL;
+    const char *p;
+    size_t path_len;
+    struct list_head candidates;
+    struct hymo_merge_target_node *cand, *tmp;
+
+    if (atomic_read(&hymo_atomiconfig) == 0) return NULL;
+    if (!pathname) return NULL;
+    
+    INIT_LIST_HEAD(&candidates);
+    path_len = strlen(pathname);
+    hash = full_name_hash(NULL, pathname, path_len);
+
+    rcu_read_lock();
+    hlist_for_each_entry_rcu(entry, &hymo_paths[hash_min(hash, HYMO_HASH_BITS)], node) {
+        if (strcmp(entry->src, pathname) == 0) {
+            target = kstrdup(entry->target, GFP_ATOMIC);
+            rcu_read_unlock();
+            return target;
+        }
+    }
+    
+    // Merge Rule Lookup (Walk up without allocation in hot path)
+    p = pathname + path_len;
+    while (p > pathname) {
+        // Find last slash
+        while (p > pathname && *p != '/') p--;
+        if (p == pathname && *p != '/') break; // No more slashes
+        
+        // Terminate to get parent (virtual)
+        size_t current_len = p - pathname;
+        if (current_len == 0) { // Root
+             // Handle root if needed, but usually we don't merge root
+            break;
+        }
+        
+        // Lookup parent in merge_dirs using substring hash
+        hash = full_name_hash(NULL, pathname, current_len);
+        hlist_for_each_entry_rcu(merge_entry, &hymo_merge_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+            // Compare substring
+            if (strlen(merge_entry->src) == current_len && 
+                strncmp(merge_entry->src, pathname, current_len) == 0) {
+                
+                // Found merge rule!
+                
+                /* If the path is just the merge directory itself (or . / ..), 
+                   do NOT redirect. We want to open the original directory 
+                   so readdir can merge entries. */
+                const char *suffix = pathname + current_len;
+                if (suffix[0] == '\0' || strcmp(suffix, "/.") == 0 || strcmp(suffix, "/..") == 0) {
+                    continue;
+                }
+
+                // Construct candidate: target + (pathname - parent)
+                size_t target_len = strlen(merge_entry->target);
+                size_t suffix_len = path_len - current_len; // includes leading slash
+                
+                cand = kmalloc(sizeof(*cand), GFP_ATOMIC);
+                if (cand) {
+                    cand->target = kmalloc(target_len + suffix_len + 1, GFP_ATOMIC);
+                    if (cand->target) {
+                        strcpy(cand->target, merge_entry->target);
+                        strcat(cand->target, suffix);
+                        list_add_tail(&cand->list, &candidates);
+                    } else {
+                        kfree(cand);
+                    }
+                }
+            }
+        }
+
+        // If we found any candidates at this level, stop walking up.
+        if (!list_empty(&candidates)) {
+            break;
+        }
+        
+        // Move p back to continue loop (skip current slash)
+        if (p > pathname) p--;
+    }
+    
+    rcu_read_unlock();
+    
+    // Check candidates (outside RCU lock, kern_path may sleep)
+    list_for_each_entry_safe(cand, tmp, &candidates, list) {
+        if (!target) {
+            struct path p;
+            if (kern_path(cand->target, LOOKUP_FOLLOW, &p) == 0) {
+                path_put(&p);
+                target = cand->target; // Take ownership
+                cand->target = NULL;   // Prevent double free
+            }
+        }
+        
+        if (cand->target) kfree(cand->target);
+        kfree(cand);
+    }
+
+    return target;
+}
+EXPORT_SYMBOL(__hymofs_resolve_target);
+
+/* Returns length of written string, or -1 if not found/error. Writes to buf. */
+int __hymofs_reverse_lookup(const char *pathname, char *buf, size_t buflen)
+{
+    struct hymo_entry *entry;
+    struct hymo_merge_entry *merge_entry;
+    u32 hash;
+    int bkt;
+    int ret = -1;
+
+    if (atomic_read(&hymo_atomiconfig) == 0) return -1;
+    if (!pathname || !buf) return -1;
+
+    hash = full_name_hash(NULL, pathname, strlen(pathname));
+
+    rcu_read_lock();
+    
+    /* Check 1-to-1 mappings */
+    hlist_for_each_entry_rcu(entry, &hymo_targets[hash_min(hash, HYMO_HASH_BITS)], target_node) {
+        if (strcmp(entry->target, pathname) == 0) {
+            if (strscpy(buf, entry->src, buflen) < 0) ret = -ENAMETOOLONG;
+            else ret = strlen(buf);
+            goto out;
+        }
+    }
+
+    /* Check merge targets (reverse mapping) */
+    hash_for_each_rcu(hymo_merge_dirs, bkt, merge_entry, node) {
+        size_t target_len = strlen(merge_entry->target);
+        if (strncmp(pathname, merge_entry->target, target_len) == 0) {
+            /* Ensure it's a directory match or exact match */
+            if (pathname[target_len] == '/' || pathname[target_len] == '\0') {
+                size_t src_len = strlen(merge_entry->src);
+                size_t suffix_len = strlen(pathname) - target_len;
+                
+                if (src_len + suffix_len + 1 > buflen) {
+                    ret = -ENAMETOOLONG;
+                } else {
+                    memcpy(buf, merge_entry->src, src_len);
+                    memcpy(buf + src_len, pathname + target_len, suffix_len);
+                    buf[src_len + suffix_len] = '\0';
+                    ret = src_len + suffix_len;
+        }
+                goto out;
+    }
+        }
+    }
+
+out:
+    rcu_read_unlock();
+    return ret;
+}
+EXPORT_SYMBOL(__hymofs_reverse_lookup);
+
+bool __hymofs_should_hide(const char *pathname, size_t len)
+{
+    if (atomic_read(&hymo_atomiconfig) == 0) return false;
+    if (!pathname) return false;
+
+    /* Root sees everything */
+    if (uid_eq(current_uid(), GLOBAL_ROOT_UID)) return false;
+
+#ifdef CONFIG_HYMOFS_USE_KSU
+    if (susfs_is_current_ksu_domain()) return false;
+#endif
+
+    /*
+     * Fast path: Only check stealth mode here (O(1))
+     * The actual hide rules are now checked via inode marking in walk_component()
+     * This avoids expensive hash table traversal on every path lookup
+     */
+    if (hymo_stealth_enabled) {
+        size_t name_len = strlen(hymo_current_mirror_name);
+        size_t path_len = strlen(hymo_current_mirror_path);
+
+        if ((len == name_len && strcmp(pathname, hymo_current_mirror_name) == 0) ||
+            (len == path_len && strcmp(pathname, hymo_current_mirror_path) == 0)) {
+            return true;
+        }
+    }
+
+    return false;
+}
+EXPORT_SYMBOL(__hymofs_should_hide);
+
+bool __hymofs_should_spoof_mtime(const char *pathname)
+{
+    struct hymo_inject_entry *entry;
+    u32 hash;
+    bool found = false;
+
+    if (atomic_read(&hymo_atomiconfig) == 0) return false;
+    if (!pathname) return false;
+
+#ifdef CONFIG_HYMOFS_USE_KSU
+    if (susfs_is_current_ksu_domain()) return false;
+#endif
+
+    hash = full_name_hash(NULL, pathname, strlen(pathname));
+
+    rcu_read_lock();
+    hlist_for_each_entry_rcu(entry, &hymo_inject_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+        if (strcmp(entry->dir, pathname) == 0) {
+            found = true;
+            break;
+        }
+    }
+    rcu_read_unlock();
+    return found;
+}
+EXPORT_SYMBOL(__hymofs_should_spoof_mtime);
+
+static bool __hymofs_should_replace(const char *pathname)
+{
+    struct hymo_entry *entry;
+    u32 hash;
+    bool found = false;
+
+    if (atomic_read(&hymo_atomiconfig) == 0) return false;
+    if (!pathname) return false;
+
+#ifdef CONFIG_HYMOFS_USE_KSU
+    if (susfs_is_current_ksu_domain()) return false;
+#endif
+
+    hash = full_name_hash(NULL, pathname, strlen(pathname));
+
+    rcu_read_lock();
+    hlist_for_each_entry_rcu(entry, &hymo_paths[hash_min(hash, HYMO_HASH_BITS)], node) {
+        if (strcmp(entry->src, pathname) == 0) {
+            found = true;
+            break;
+        }
+    }
+    rcu_read_unlock();
+    return found;
+}
+
+struct hymo_merge_ctx {
+    struct dir_context ctx;
+    struct list_head *head;
+    const char *dir_path;
+};
+
+static bool hymo_merge_filldir(struct dir_context *ctx, const char *name, int namlen,
+		      loff_t offset, u64 ino, unsigned int d_type)
+{
+    struct hymo_merge_ctx *mctx = container_of(ctx, struct hymo_merge_ctx, ctx);
+    struct hymo_name_list *item;
+
+    if (namlen == 1 && name[0] == '.') return true;
+    if (namlen == 2 && name[0] == '.' && name[1] == '.') return true;
+
+    /* Skip .replace marker */
+    if (namlen == 8 && strncmp(name, ".replace", 8) == 0) return true;
+
+    /* Check for whiteout (char dev 0:0) */
+    if (d_type == DT_CHR) {
+        char *path = kasprintf(GFP_KERNEL, "%s/%.*s", mctx->dir_path, namlen, name);
+        if (path) {
+            struct kstat stat;
+            struct path p;
+            if (kern_path(path, LOOKUP_FOLLOW, &p) == 0) {
+                if (vfs_getattr(&p, &stat, STATX_TYPE, AT_STATX_SYNC_AS_STAT) == 0) {
+                    if (S_ISCHR(stat.mode) && stat.rdev == 0) {
+                        /* It is a whiteout, skip injection */
+                        path_put(&p);
+                        kfree(path);
+                        return true;
+                    }
+                }
+                path_put(&p);
+            }
+            kfree(path);
+        }
+    }
+
+    /* Check for duplicates */
+    {
+        struct hymo_name_list *pos;
+        list_for_each_entry(pos, mctx->head, list) {
+            if (strlen(pos->name) == namlen && strncmp(pos->name, name, namlen) == 0) {
+                return true; // Already exists
+            }
+        }
+    }
+
+    item = kmalloc(sizeof(*item), GFP_KERNEL);
+    if (item) {
+        item->name = kstrndup(name, namlen, GFP_KERNEL);
+        item->type = d_type;
+        if (item->name) {
+            list_add(&item->list, mctx->head);
+        } else {
+            kfree(item);
+        }
+    }
+    return true;
+}
+
+int hymofs_populate_injected_list(const char *dir_path, struct dentry *parent, struct list_head *head)
+{
+    struct hymo_entry *entry;
+    struct hymo_inject_entry *inject_entry;
+    struct hymo_merge_entry *merge_entry;
+    struct hymo_name_list *item;
+    u32 hash;
+    int bkt;
+    bool should_inject = false;
+    struct list_head merge_targets;
+    struct hymo_merge_target_node *target_node, *tmp_node;
+    size_t dir_len;
+    
+    if (atomic_read(&hymo_atomiconfig) == 0) return 0;
+    if (!dir_path) return 0;
+
+    INIT_LIST_HEAD(&merge_targets);
+    dir_len = strlen(dir_path);
+    hash = full_name_hash(NULL, dir_path, dir_len);
+
+    rcu_read_lock();
+    
+    hlist_for_each_entry_rcu(inject_entry, &hymo_inject_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+        if (strcmp(inject_entry->dir, dir_path) == 0) {
+            should_inject = true;
+            break;
+        }
+    }
+    
+    // Check for merge rule
+    hlist_for_each_entry_rcu(merge_entry, &hymo_merge_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+        if (strcmp(merge_entry->src, dir_path) == 0) {
+            target_node = kmalloc(sizeof(*target_node), GFP_ATOMIC);
+            if (target_node) {
+                target_node->target = kstrdup(merge_entry->target, GFP_ATOMIC);
+                list_add_tail(&target_node->list, &merge_targets);
+             should_inject = true;
+        }
+        }
+    }
+
+    if (should_inject) {
+        // Static injections
+        hash_for_each_rcu(hymo_paths, bkt, entry, node) {
+            if (strncmp(entry->src, dir_path, dir_len) == 0) {
+                char *name = NULL;
+                if (dir_len == 1 && dir_path[0] == '/') {
+                    name = entry->src + 1;
+                } else if (entry->src[dir_len] == '/') {
+                    name = entry->src + dir_len + 1;
+                }
+
+                if (name && *name && strchr(name, '/') == NULL) {
+                    /* Check for duplicates */
+                    bool exists = false;
+                    struct hymo_name_list *pos;
+                    list_for_each_entry(pos, head, list) {
+                        if (strcmp(pos->name, name) == 0) {
+                            exists = true;
+                            break;
+                        }
+                    }
+
+                    if (!exists) {
+                    item = kmalloc(sizeof(*item), GFP_ATOMIC);
+                    if (item) {
+                        item->name = kstrdup(name, GFP_ATOMIC);
+                        item->type = entry->type;
+                        if (item->name) {
+                            list_add(&item->list, head);
+                        }
+                        else kfree(item);
+                        }
+                    }
+                }
+            }
+        }
+    }
+
+    rcu_read_unlock();
+
+    // Dynamic merge (outside RCU lock, kern_path/iterate_dir may sleep)
+    list_for_each_entry_safe(target_node, tmp_node, &merge_targets, list) {
+        if (target_node->target) {
+            struct path path;
+            if (kern_path(target_node->target, LOOKUP_FOLLOW, &path) == 0) {
+                /* Use init_cred (root) to ensure we can read the module directory 
+                   regardless of the calling process's permissions */
+                const struct cred *cred = get_task_cred(&init_task);
+                struct file *f = dentry_open(&path, O_RDONLY | O_DIRECTORY, cred);
+                if (!IS_ERR(f)) {
+                    struct hymo_merge_ctx mctx = {
+                        .ctx.actor = hymo_merge_filldir,
+                        .head = head,
+                        .dir_path = target_node->target
+                    };
+                    iterate_dir(f, &mctx.ctx);
+                    fput(f);
+                }
+                put_cred(cred);
+                path_put(&path);
+            }
+            kfree(target_node->target);
+        }
+        kfree(target_node);
+    }
+
+    return 0;
+}
+EXPORT_SYMBOL(hymofs_populate_injected_list);
+
+struct filename *hymofs_handle_getname(struct filename *result)
+{
+    char *target = NULL;
+
+    if (IS_ERR(result)) return result;
+
+    /* HymoFS Path Hiding Hook */
+    /* Use fast path inline check first */
+    if (hymofs_should_hide(result->name)) {
+        putname(result);
+        /* Return ENOENT directly */
+        return ERR_PTR(-ENOENT);
+    } else {
+        if (result->name[0] != '/') {
+            /* Handle relative paths by prepending CWD */
+            char *buf = kmalloc(PAGE_SIZE, GFP_KERNEL);
+            if (buf) {
+                struct path pwd;
+                /* get_fs_pwd is not exported in newer kernels, use manual locking */
+                spin_lock(&current->fs->lock);
+                pwd = current->fs->pwd;
+                path_get(&pwd);
+                spin_unlock(&current->fs->lock);
+
+                /* Use d_path (hooked) to get the virtual path of CWD */
+                char *cwd = d_path(&pwd, buf, PAGE_SIZE);
+                if (!IS_ERR(cwd)) {
+                    int cwd_len = strlen(cwd);
+                    const char *name = result->name;
+                    
+                    /* Skip ./ prefix */
+                    if (name[0] == '.' && name[1] == '/') {
+                        name += 2;
+                    }
+
+                    int name_len = strlen(name);
+                    
+                    /* Move to beginning of buffer to allow appending */
+                    if (cwd != buf) {
+                        memmove(buf, cwd, cwd_len + 1);
+                        cwd = buf;
+                    }
+
+                    if (cwd_len + 1 + name_len < PAGE_SIZE) {
+                        /* Construct absolute path: cwd + / + name */
+                        if (cwd_len > 0 && cwd[cwd_len - 1] != '/') {
+                            strcat(cwd, "/");
+                        }
+                        strcat(cwd, name);
+                        
+                        /* Try to resolve the constructed absolute path */
+                        target = hymofs_resolve_target(cwd);
+                        
+                    }
+                }
+                path_put(&pwd);
+                kfree(buf);
+            }
+        }
+        
+        if (!target) {
+        target = hymofs_resolve_target(result->name);
+        }
+
+        if (target) {
+            putname(result);
+            result = getname_kernel(target);
+            kfree(target);
+        }
+    }
+    return result;
+}
+EXPORT_SYMBOL(hymofs_handle_getname);
+
+/* Resolve relative path with dirfd for fstatat() merge support */
+struct filename *hymofs_resolve_relative(int dfd, const char *name)
+{
+    struct fd f;
+    struct filename *result = NULL;
+    char *buf, *dir_path, *target;
+    size_t dir_len, name_len;
+
+    f = fdget(dfd);
+    if (!f.file)
+        return NULL;
+
+    buf = kmalloc(PATH_MAX, GFP_KERNEL);
+    if (!buf)
+        goto out_fdput;
+
+    dir_path = d_path(&f.file->f_path, buf, PATH_MAX);
+    if (IS_ERR(dir_path))
+        goto out_free;
+
+    dir_len = strlen(dir_path);
+    name_len = strlen(name);
+    if (dir_len + 1 + name_len >= PATH_MAX)
+        goto out_free;
+
+    /* Build full path in-place */
+    if (dir_path != buf)
+        memmove(buf, dir_path, dir_len);
+    if (dir_len > 0 && buf[dir_len - 1] != '/')
+        buf[dir_len++] = '/';
+    memcpy(buf + dir_len, name, name_len + 1);
+
+    target = __hymofs_resolve_target(buf);
+    if (target) {
+        result = getname_kernel(target);
+        if (IS_ERR(result))
+            result = NULL;
+        kfree(target);
+    }
+
+out_free:
+    kfree(buf);
+out_fdput:
+    fdput(f);
+    return result;
+}
+EXPORT_SYMBOL(hymofs_resolve_relative);
+
+/* Bloom filter helper - add a filename */
+static __always_inline void bloom_add(unsigned long *filter, const char *name, int namlen)
+{
+    u32 h1 = full_name_hash(NULL, name, namlen);
+    __set_bit(h1 & HYMO_BLOOM_MASK, filter);  /* Non-atomic, faster */
+    __set_bit((h1 >> 16) & HYMO_BLOOM_MASK, filter);
+}
+
+/* Bloom filter helper - test if filename might exist */
+static __always_inline bool bloom_test(const unsigned long *filter, const char *name, int namlen)
+{
+    u32 h1 = full_name_hash(NULL, name, namlen);
+    /* Use bitwise AND to avoid branch */
+    return test_bit(h1 & HYMO_BLOOM_MASK, filter) & 
+           test_bit((h1 >> 16) & HYMO_BLOOM_MASK, filter);
+}
+
+/* Callback context for enumerating merge target directory */
+struct bloom_fill_ctx {
+    struct dir_context ctx;
+    unsigned long *filter;
+};
+
+/* Callback to add each filename to bloom filter */
+static bool bloom_filldir(struct dir_context *ctx, const char *name, int namlen,
+                          loff_t offset, u64 ino, unsigned int d_type)
+{
+    struct bloom_fill_ctx *bctx = container_of(ctx, struct bloom_fill_ctx, ctx);
+    /* Skip . and .. */
+    if (namlen == 1 && name[0] == '.')
+        return true;
+    if (namlen == 2 && name[0] == '.' && name[1] == '.')
+        return true;
+    bloom_add(bctx->filter, name, namlen);
+    return true;
+}
+
+void __hymofs_prepare_readdir(struct hymo_readdir_context *ctx, struct file *file)
+{
+    struct inode *dir_inode;
+    int i;
+    
+    ctx->file = file;
+    ctx->path_buf = NULL;
+    ctx->dir_path = NULL;
+    ctx->dir_path_len = 0;
+    INIT_LIST_HEAD(&ctx->merge_targets);
+    ctx->is_replace_mode = false;
+    ctx->dir_has_hidden = false;
+    ctx->has_merge_files = false;
+    
+    /* Initialize bloom filter */
+    memset(ctx->bloom_filter, 0, sizeof(ctx->bloom_filter));
+    
+    /* Initialize merge files hash table */
+    for (i = 0; i < HYMO_MERGE_HASH_SIZE; i++)
+        INIT_HLIST_HEAD(&ctx->merge_files[i]);
+
+    /* Fast path: Check if this directory has any hidden entries */
+    if (file && file->f_path.dentry) {
+        dir_inode = d_inode(file->f_path.dentry);
+        if (dir_inode && dir_inode->i_mapping) {
+            ctx->dir_has_hidden = test_bit(AS_FLAGS_HYMO_DIR_HAS_HIDDEN, 
+                                           &dir_inode->i_mapping->flags);
+        }
+    }
+
+    ctx->path_buf = (char *)__get_free_page(GFP_KERNEL);
+    if (ctx->path_buf && file && file->f_path.dentry) {
+        char *p = d_path(&file->f_path, ctx->path_buf, PAGE_SIZE);
+        if (!IS_ERR(p)) {
+            int len = strlen(p);
+            memmove(ctx->path_buf, p, len + 1);
+            ctx->dir_path = ctx->path_buf;
+            ctx->dir_path_len = len;
+            // hymo_log("readdir prepare: %s\n", ctx->dir_path);
+
+            /* Check for merge rule */
+            {
+                struct hymo_merge_entry *entry;
+                u32 hash = full_name_hash(NULL, ctx->dir_path, ctx->dir_path_len);
+                
+                rcu_read_lock();
+                hlist_for_each_entry_rcu(entry, &hymo_merge_dirs[hash_min(hash, HYMO_HASH_BITS)], node) {
+                    if (strcmp(entry->src, ctx->dir_path) == 0) {
+                        struct hymo_merge_target_node *node = kmalloc(sizeof(*node), GFP_ATOMIC);
+                        if (node) {
+                            struct path target_path;
+                            node->target = kstrdup(entry->target, GFP_ATOMIC);
+                            node->target_dentry = NULL;
+                            /* Cache the target dentry for fast lookup */
+                            if (kern_path(entry->target, LOOKUP_FOLLOW, &target_path) == 0) {
+                                node->target_dentry = dget(target_path.dentry);
+                                path_put(&target_path);
+                            }
+                            list_add_tail(&node->list, &ctx->merge_targets);
+                        }
+                    }
+                }
+                rcu_read_unlock();
+
+                /* Check for .replace marker in merge targets */
+                if (!list_empty(&ctx->merge_targets)) {
+                    struct hymo_merge_target_node *node;
+                    list_for_each_entry(node, &ctx->merge_targets, list) {
+                        char *replace_path = kasprintf(GFP_KERNEL, "%s/.replace", node->target);
+                        if (replace_path) {
+                            struct path path;
+                            if (kern_path(replace_path, LOOKUP_FOLLOW, &path) == 0) {
+                                ctx->is_replace_mode = true;
+                                hymo_log("replace mode enabled for %s (found %s)\n", ctx->dir_path, replace_path);
+                                path_put(&path);
+                            }
+                            kfree(replace_path);
+                            if (ctx->is_replace_mode) break;
+                        }
+                    }
+                    
+                    /* Mark that we have merge files to check */
+                    if (!ctx->is_replace_mode) {
+                        ctx->has_merge_files = true;
+                        
+                        /* Build bloom filter by enumerating merge target directories */
+                        list_for_each_entry(node, &ctx->merge_targets, list) {
+                            if (node->target_dentry) {
+                                struct file *target_file;
+                                struct path target_path = {
+                                    .mnt = file->f_path.mnt,
+                                    .dentry = node->target_dentry
+                                };
+                                target_file = dentry_open(&target_path, O_RDONLY | O_DIRECTORY, current_cred());
+                                if (!IS_ERR(target_file)) {
+                                    struct bloom_fill_ctx bctx = {
+                                        .ctx.actor = bloom_filldir,
+                                        .filter = ctx->bloom_filter
+                                    };
+                                    iterate_dir(target_file, &bctx.ctx);
+                                    fput(target_file);
+                                }
+                            }
+                        }
+                    }
+                }
+            }
+        } else {
+            free_page((unsigned long)ctx->path_buf);
+            ctx->path_buf = NULL;
+        }
+    }
+}
+EXPORT_SYMBOL(__hymofs_prepare_readdir);
+
+void __hymofs_cleanup_readdir(struct hymo_readdir_context *ctx)
+{
+    struct hymo_merge_target_node *node, *tmp;
+    
+    if (ctx->path_buf) free_page((unsigned long)ctx->path_buf);
+    list_for_each_entry_safe(node, tmp, &ctx->merge_targets, list) {
+        if (node->target_dentry)
+            dput(node->target_dentry);
+        kfree(node->target);
+        kfree(node);
+    }
+}
+EXPORT_SYMBOL(__hymofs_cleanup_readdir);
+
+bool __hymofs_check_filldir(struct hymo_readdir_context *ctx, const char *name, int namlen)
+{
+    struct dentry *child;
+    struct inode *inode;
+
+    /* Skip . and .. - use single comparison where possible */
+    if (unlikely(namlen <= 2 && name[0] == '.')) {
+        if (namlen == 1 || (namlen == 2 && name[1] == '.'))
+            return false;
+    }
+
+    /* If we are in replace mode, hide all original entries */
+    if (unlikely(ctx->is_replace_mode))
+        return true;
+
+    /* Fast path: If directory has no hidden entries and no merge files, skip all checks */
+    if (likely(!ctx->dir_has_hidden && !ctx->has_merge_files))
+        return false;  /* O(1) skip! */
+
+    /* Fast path: Use inode marking (O(1) bit test) */
+    if (ctx->dir_has_hidden && ctx->file && ctx->file->f_path.dentry) {
+        child = d_hash_and_lookup(ctx->file->f_path.dentry, 
+                                  &(struct qstr)QSTR_INIT(name, namlen));
+        if (child) {
+            inode = d_inode(child);
+            if (inode && inode->i_mapping &&
+                test_bit(AS_FLAGS_HYMO_HIDE, &inode->i_mapping->flags)) {
+                dput(child);
+                return true;
+            }
+            dput(child);
+        }
+    }
+
+    /* Merge target check - files that exist in merge target should be hidden */
+    if (ctx->has_merge_files) {
+        /* Ultra fast path: Bloom filter says definitely not in merge target */
+        if (!bloom_test(ctx->bloom_filter, name, namlen)) {
+            return false;  /* O(1) skip - bloom filter negative */
+        }
+        
+        /* Bloom filter positive - need to confirm with d_hash_and_lookup */
+        struct hymo_merge_target_node *node;
+        list_for_each_entry(node, &ctx->merge_targets, list) {
+            /* Fast path: use cached dentry + d_hash_and_lookup */
+            if (node->target_dentry) {
+                struct dentry *child = d_hash_and_lookup(node->target_dentry,
+                                           &(struct qstr)QSTR_INIT(name, namlen));
+                if (child) {
+                    dput(child);
+                    return true;
+                }
+            }
+        }
+    }
+
+    return false;
+}
+EXPORT_SYMBOL(__hymofs_check_filldir);
+
+struct linux_dirent {
+	unsigned long	d_ino;
+	unsigned long	d_off;
+	unsigned short	d_reclen;
+	char		d_name[];
+};
+
+/* Inject virtual entries into getdents system call */
+int hymofs_inject_entries(struct hymo_readdir_context *ctx, void __user **dir_ptr, int *count, loff_t *pos)
+{
+    struct linux_dirent __user *current_dir = *dir_ptr;
+    struct list_head head;
+    struct hymo_name_list *item, *tmp;
+    loff_t current_idx = 0;
+    loff_t start_idx;
+    int injected = 0;
+    int error = 0;
+    int initial_count = *count;
+    bool is_transition = (*pos < HYMO_MAGIC_POS);
+    struct dentry *parent;
+
+    if (!ctx->file) return 0;
+    parent = ctx->file->f_path.dentry;
+
+    if (is_transition) {
+        start_idx = 0;
+    } else {
+        start_idx = *pos - HYMO_MAGIC_POS;
+    }
+
+    INIT_LIST_HEAD(&head);
+    hymofs_populate_injected_list(ctx->dir_path, parent, &head);
+
+    list_for_each_entry_safe(item, tmp, &head, list) {
+        if (current_idx >= start_idx) {
+            int name_len = strlen(item->name);
+            int reclen = ALIGN(offsetof(struct linux_dirent, d_name) + name_len + 2, sizeof(long));
+            if (*count >= reclen) {
+                struct linux_dirent d;
+                d.d_ino = 1;
+                d.d_off = HYMO_MAGIC_POS + current_idx + 1;
+                d.d_reclen = reclen;
+                if (copy_to_user(current_dir, &d, offsetof(struct linux_dirent, d_name)) ||
+                    copy_to_user(current_dir->d_name, item->name, name_len) ||
+                    put_user(0, current_dir->d_name + name_len) ||
+                    put_user(item->type, (char __user *)current_dir + reclen - 1)) {
+                        error = -EFAULT;
+                        break;
+                }
+                current_dir = (struct linux_dirent __user *)((char __user *)current_dir + reclen);
+                *count -= reclen;
+                injected++;
+            } else {
+                break;
+            }
+        }
+        current_idx++;
+        list_del(&item->list);
+        kfree(item->name);
+        kfree(item);
+    }
+    
+    list_for_each_entry_safe(item, tmp, &head, list) {
+        list_del(&item->list);
+        kfree(item->name);
+        kfree(item);
+    }
+
+    if (error == 0) {
+        if (injected > 0) {
+            if (is_transition) {
+                *pos = HYMO_MAGIC_POS + injected;
+            } else {
+                *pos += injected;
+            }
+        }
+        error = initial_count - *count;
+    }
+    
+    *dir_ptr = current_dir;
+    return error;
+}
+EXPORT_SYMBOL(hymofs_inject_entries);
+
+/* Inject virtual entries into getdents64 system call */
+int hymofs_inject_entries64(struct hymo_readdir_context *ctx, void __user **dir_ptr, int *count, loff_t *pos)
+{
+    struct linux_dirent64 __user *current_dir = *dir_ptr;
+    struct list_head head;
+    struct hymo_name_list *item, *tmp;
+    loff_t current_idx = 0;
+    loff_t start_idx;
+    int injected = 0;
+    int error = 0;
+    int initial_count = *count;
+    bool is_transition = (*pos < HYMO_MAGIC_POS);
+    struct dentry *parent;
+
+    if (!ctx->file) return 0;
+    parent = ctx->file->f_path.dentry;
+
+    if (is_transition) {
+        start_idx = 0;
+    } else {
+        start_idx = *pos - HYMO_MAGIC_POS;
+    }
+
+    INIT_LIST_HEAD(&head);
+    hymofs_populate_injected_list(ctx->dir_path, parent, &head);
+
+    list_for_each_entry_safe(item, tmp, &head, list) {
+        if (current_idx >= start_idx) {
+            int name_len = strlen(item->name);
+            int reclen = ALIGN(offsetof(struct linux_dirent64, d_name) + name_len + 1, sizeof(u64));
+            if (*count >= reclen) {
+                struct linux_dirent64 d;
+                d.d_ino = 1;
+                d.d_off = HYMO_MAGIC_POS + current_idx + 1;
+                d.d_reclen = reclen;
+                d.d_type = item->type;
+                if (copy_to_user(current_dir, &d, offsetof(struct linux_dirent64, d_name)) ||
+                    copy_to_user(current_dir->d_name, item->name, name_len) ||
+                    put_user(0, current_dir->d_name + name_len)) {
+                        error = -EFAULT;
+                        break;
+                }
+                current_dir = (struct linux_dirent64 __user *)((char __user *)current_dir + reclen);
+                *count -= reclen;
+                injected++;
+            } else {
+                break;
+            }
+        }
+        current_idx++;
+        list_del(&item->list);
+        kfree(item->name);
+        kfree(item);
+    }
+    
+    list_for_each_entry_safe(item, tmp, &head, list) {
+        list_del(&item->list);
+        kfree(item->name);
+        kfree(item);
+    }
+
+    if (error == 0) {
+        if (injected > 0) {
+            if (is_transition) {
+                *pos = HYMO_MAGIC_POS + injected;
+            } else {
+                *pos += injected;
+            }
+        }
+        error = initial_count - *count;
+    }
+    
+    *dir_ptr = current_dir;
+    return error;
+}
+EXPORT_SYMBOL(hymofs_inject_entries64);
+
+static dev_t __attribute__((unused)) get_dev_for_path(const char *path_str) {
+    struct path path;
+    dev_t dev = 0;
+    if (kern_path(path_str, LOOKUP_FOLLOW, &path) == 0) {
+        if (path.dentry && path.dentry->d_sb) {
+            dev = path.dentry->d_sb->s_dev;
+        }
+        path_put(&path);
+    }
+    return dev;
+}
+
+/* Update timestamps for injected directories to appear current */
+extern char *d_absolute_path(const struct path *, char *, int);
+void hymofs_spoof_stat(const struct path *path, struct kstat *stat)
+{
+    if (!hymo_stealth_enabled) return;
+    if (atomic_read(&hymo_atomiconfig) == 0) return;
+
+    char *buf = kmalloc(PAGE_SIZE, GFP_KERNEL);
+    if (buf && path && path->dentry) {
+        /* Use d_absolute_path to bypass our own d_path hook and get the real physical path */
+        char *p = d_absolute_path(path, buf, PAGE_SIZE);
+        if (!IS_ERR(p)) {
+            /* HymoFS: Check if this path is a merge target (physical path) and map back to virtual */
+            char *virtual_buf = kmalloc(PAGE_SIZE, GFP_KERNEL);
+            bool is_injected = false;
+            
+            if (virtual_buf) {
+                if (__hymofs_reverse_lookup(p, virtual_buf, PAGE_SIZE) > 0) {
+                    p = virtual_buf; /* Switch to virtual path */
+                    is_injected = true;
+                }
+            }
+
+            /* Only spoof attributes for files we injected */
+            if (is_injected) {
+                /* Always look up parent to get correct fs attributes (dev, uid, gid) */
+                char *last_slash = strrchr(p, '/');
+                if (last_slash) {
+                    if (last_slash == p) {
+                        /* Parent is root */
+                        struct path parent_path;
+                        if (kern_path("/", LOOKUP_FOLLOW, &parent_path) == 0) {
+                            struct inode *inode = d_backing_inode(parent_path.dentry);
+                            stat->uid = inode->i_uid;
+                            stat->gid = inode->i_gid;
+                            stat->dev = inode->i_sb->s_dev;
+                            path_put(&parent_path);
+                        }
+                    } else {
+                        *last_slash = '\0';
+                        struct path parent_path;
+                        if (kern_path(p, LOOKUP_FOLLOW, &parent_path) == 0) {
+                            struct inode *inode = d_backing_inode(parent_path.dentry);
+                            stat->uid = inode->i_uid;
+                            stat->gid = inode->i_gid;
+                            stat->dev = inode->i_sb->s_dev;
+                            path_put(&parent_path);
+                        } else {
+                            /* Fallback if parent lookup fails (rare) */
+                            if (strncmp(p, "/system/", 8) == 0 || 
+                                strncmp(p, "/vendor/", 8) == 0 ||
+                                strncmp(p, "/product/", 9) == 0 ||
+                                strncmp(p, "/odm/", 5) == 0 ||
+                                strncmp(p, "/apex/", 6) == 0) {
+                                stat->uid = KUIDT_INIT(0);
+                                stat->gid = KGIDT_INIT(0);
+                            }
+                        }
+                        *last_slash = '/';
+                    }
+                }
+                /* Obfuscate inode for injected files too */
+                stat->ino ^= 0x48594D4F;
+            }
+
+            if (hymofs_should_spoof_mtime(p)) {
+                ktime_get_real_ts64(&stat->mtime);
+                stat->ctime = stat->mtime;
+            }
+            /* HymoFS: Inode obfuscation for redirected paths */
+            if (__hymofs_should_replace(p)) {
+                /* XOR with a magic number to make inode look different from target */
+                stat->ino ^= 0x48594D4F;
+                
+                /* Fixup permissions for /system paths to ensure they look like root-owned */
+                if (strncmp(p, "/system/", 8) == 0) {
+                    stat->uid = KUIDT_INIT(0);
+                    stat->gid = KGIDT_INIT(0);
+                }
+            }
+            
+            if (virtual_buf) kfree(virtual_buf);
+        }
+        kfree(buf);
+    }
+}
+EXPORT_SYMBOL(hymofs_spoof_stat);
+
+bool hymofs_is_overlay_xattr(struct dentry *dentry, const char *name)
+{
+    struct hymo_xattr_sb_entry *sb_entry;
+    bool found = false;
+    unsigned long flags;
+
+    if (!name) return false;
+    if (strncmp(name, "trusted.overlay.", 16) != 0) return false;
+    
+    if (!dentry) return false;
+
+    rcu_read_lock();
+    hlist_for_each_entry_rcu(sb_entry, &hymo_xattr_sbs[hash_min((unsigned long)dentry->d_sb, HYMO_HASH_BITS)], node) {
+        if (sb_entry->sb == dentry->d_sb) {
+            found = true;
+            break;
+        }
+    }
+    rcu_read_unlock();
+    
+    return found;
+}
+EXPORT_SYMBOL(hymofs_is_overlay_xattr);
+
+ssize_t hymofs_filter_xattrs(struct dentry *dentry, char *klist, ssize_t len)
+{
+    struct hymo_xattr_sb_entry *sb_entry;
+    bool should_filter = false;
+    char *p = klist;
+    char *end = klist + len;
+    char *out = klist;
+    ssize_t new_len = 0;
+    
+    if (!dentry) return len;
+
+    rcu_read_lock();
+    hlist_for_each_entry_rcu(sb_entry, &hymo_xattr_sbs[hash_min((unsigned long)dentry->d_sb, HYMO_HASH_BITS)], node) {
+        if (sb_entry->sb == dentry->d_sb) {
+            should_filter = true;
+            break;
+        }
+    }
+    rcu_read_unlock();
+
+    if (!should_filter) return len;
+
+    while (p < end) {
+        size_t slen = strlen(p);
+        if (strncmp(p, "trusted.overlay.", 16) != 0) {
+            if (out != p)
+                memmove(out, p, slen + 1);
+            out += slen + 1;
+            new_len += slen + 1;
+        }
+        p += slen + 1;
+    }
+    return new_len;
+}
+EXPORT_SYMBOL(hymofs_filter_xattrs);
+
+#ifdef CONFIG_HYMOFS_LSMBPS
+int hymofs_check_bypass(struct file *file)
+{
+    char *buf, *path;
+    char *resolve_buf;
+    int ret = 0;
+    int res_len;
+
+    if (!file) return 0;
+    if (atomic_read(&hymo_atomiconfig) == 0) return 0;
+
+    buf = (char *)__get_free_page(GFP_ATOMIC);
+    if (!buf) return 0;
+
+    resolve_buf = (char *)__get_free_page(GFP_ATOMIC);
+    if (!resolve_buf) {
+        free_page((unsigned long)buf);
+        return 0;
+    }
+
+    path = d_path(&file->f_path, buf, PAGE_SIZE);
+    if (!IS_ERR(path)) {
+        res_len = __hymofs_reverse_lookup(path, resolve_buf, PAGE_SIZE);
+        if (res_len > 0) {
+            hymo_log("SELinux Bypass: Allowing access to %s\n", path);
+            ret = 1;
+        }
+    }
+
+    free_page((unsigned long)resolve_buf);
+    free_page((unsigned long)buf);
+    return ret;
+}
+EXPORT_SYMBOL(hymofs_check_bypass);
+
+int hymofs_check_inode_bypass(struct inode *inode)
+{
+    struct hymo_xattr_sb_entry *sb_entry;
+    int ret = 0;
+
+    if (!inode || !inode->i_sb) return 0;
+    if (atomic_read(&hymo_atomiconfig) == 0) return 0;
+
+    rcu_read_lock();
+    hlist_for_each_entry_rcu(sb_entry, &hymo_xattr_sbs[hash_min((unsigned long)inode->i_sb, HYMO_HASH_BITS)], node) {
+        if (sb_entry->sb == inode->i_sb) {
+            hymo_log("SELinux Inode Bypass: Allowing access to inode %lu on sb %p\n", inode->i_ino, inode->i_sb);
+            ret = 1;
+            break;
+        }
+    }
+    rcu_read_unlock();
+    
+    return ret;
+}
+EXPORT_SYMBOL(hymofs_check_inode_bypass);
+
+int hymofs_check_setxattr_bypass(struct dentry *dentry, const char *name)
+{
+    struct hymo_xattr_sb_entry *sb_entry;
+    int ret = 0;
+
+    if (!dentry || !dentry->d_sb) return 0;
+    if (atomic_read(&hymo_atomiconfig) == 0) return 0;
+
+    // Only bypass for security.selinux
+    if (strcmp(name, XATTR_NAME_SELINUX) != 0) return 0;
+
+    rcu_read_lock();
+    hlist_for_each_entry_rcu(sb_entry, &hymo_xattr_sbs[hash_min((unsigned long)dentry->d_sb, HYMO_HASH_BITS)], node) {
+        if (sb_entry->sb == dentry->d_sb) {
+            hymo_log("SELinux Setxattr Bypass: Allowing setxattr on sb %p\n", dentry->d_sb);
+            ret = 1;
+            break;
+        }
+    }
+    rcu_read_unlock();
+    
+    return ret;
+}
+EXPORT_SYMBOL(hymofs_check_setxattr_bypass);
+#endif /* CONFIG_HYMOFS_LSMBPS */
+
+#endif /* CONFIG_HYMOFS */
diff -ruN src_origin_with_susfs/fs/hymofs.h src_modified_with_susfs/fs/hymofs.h
--- src_origin_with_susfs/fs/hymofs.h	1970-01-01 08:00:00.000000000 +0800
+++ src_modified_with_susfs/fs/hymofs.h	2025-12-28 11:19:46.625721984 +0800
@@ -0,0 +1,166 @@
+#ifndef _LINUX_HYMOFS_H
+#define _LINUX_HYMOFS_H
+
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/atomic.h>
+
+#ifdef CONFIG_HYMOFS
+
+#define HYMO_MAGIC_POS 0x7000000000000000ULL
+
+#define HYMO_DEFAULT_MIRROR_NAME "hymo_mirror"
+#define HYMO_DEFAULT_MIRROR_PATH "/dev/" HYMO_DEFAULT_MIRROR_NAME
+
+struct hymo_merge_target_node {
+    struct list_head list;
+    char *target;
+    struct dentry *target_dentry;  /* Cached dentry for fast lookup */
+};
+
+/* Bloom filter for merge target filenames - ultra fast O(1) check */
+#define HYMO_BLOOM_BITS 10  /* 1024 bits = 128 bytes */
+#define HYMO_BLOOM_SIZE (1 << HYMO_BLOOM_BITS)
+#define HYMO_BLOOM_MASK (HYMO_BLOOM_SIZE - 1)
+
+/* Hash table for merge target filenames - O(1) lookup */
+#define HYMO_MERGE_HASH_BITS 6
+#define HYMO_MERGE_HASH_SIZE (1 << HYMO_MERGE_HASH_BITS)
+
+struct hymo_merge_file_entry {
+    struct hlist_node node;
+    char *name;
+    int namlen;
+};
+
+struct hymo_readdir_context {
+    struct file *file;
+    char *path_buf;
+    char *dir_path;
+    int dir_path_len;
+    bool entry_written;
+    struct list_head merge_targets;
+    bool is_replace_mode;
+    bool dir_has_hidden;  /* Fast path: skip hide check if false */
+    bool has_merge_files; /* Fast path: skip merge check if false */
+    unsigned long bloom_filter[HYMO_BLOOM_SIZE / BITS_PER_LONG]; /* Bloom filter for merge filenames */
+    struct hlist_head merge_files[HYMO_MERGE_HASH_SIZE]; /* Pre-built hash of merge target filenames */
+};
+
+extern atomic_t hymo_atomiconfig;
+
+void __hymofs_prepare_readdir(struct hymo_readdir_context *ctx, struct file *file);
+void __hymofs_cleanup_readdir(struct hymo_readdir_context *ctx);
+bool __hymofs_check_filldir(struct hymo_readdir_context *ctx, const char *name, int namlen);
+int hymofs_inject_entries(struct hymo_readdir_context *ctx, void __user **dir_ptr, int *count, loff_t *pos);
+int hymofs_inject_entries64(struct hymo_readdir_context *ctx, void __user **dir_ptr, int *count, loff_t *pos);
+void hymofs_spoof_stat(const struct path *path, struct kstat *stat);
+ssize_t hymofs_filter_xattrs(struct dentry *dentry, char *klist, ssize_t len);
+bool hymofs_is_overlay_xattr(struct dentry *dentry, const char *name);
+
+struct hymo_name_list {
+    char *name;
+    unsigned char type;
+    struct list_head list;
+};
+
+struct filename;
+struct filename *hymofs_handle_getname(struct filename *result);
+struct filename *hymofs_resolve_relative(int dfd, const char *name);
+
+char *__hymofs_resolve_target(const char *pathname);
+int __hymofs_reverse_lookup(const char *pathname, char *buf, size_t buflen);
+bool __hymofs_should_hide(const char *pathname, size_t len);
+bool __hymofs_should_spoof_mtime(const char *pathname);
+int hymofs_populate_injected_list(const char *dir_path, struct dentry *parent, struct list_head *head);
+
+/* Fast O(1) inode-based hide check - core function */
+bool __hymofs_is_inode_hidden(struct inode *inode);
+
+/* Inline wrapper with fast-path checks */
+static __always_inline bool hymofs_is_inode_hidden(struct inode *inode)
+{
+    /* Fast path: NULL checks */
+    if (unlikely(!inode || !inode->i_mapping))
+        return false;
+    
+    /* Fast path: Root sees everything */
+    if (uid_eq(current_uid(), GLOBAL_ROOT_UID))
+        return false;
+    
+    /* Fast path: No rules loaded */
+    if (atomic_read(&hymo_atomiconfig) == 0)
+        return false;
+    
+    return __hymofs_is_inode_hidden(inode);
+}
+
+static inline void hymofs_prepare_readdir(struct hymo_readdir_context *ctx, struct file *file)
+{
+    ctx->path_buf = NULL;
+    ctx->file = file;
+    if (atomic_read(&hymo_atomiconfig) == 0) return;
+    __hymofs_prepare_readdir(ctx, file);
+}
+
+static inline void hymofs_cleanup_readdir(struct hymo_readdir_context *ctx)
+{
+    if (ctx->path_buf) __hymofs_cleanup_readdir(ctx);
+}
+
+static inline bool hymofs_check_filldir(struct hymo_readdir_context *ctx, const char *name, int namlen)
+{
+    if (!ctx->path_buf) return false;
+    return __hymofs_check_filldir(ctx, name, namlen);
+}
+
+static inline char *hymofs_resolve_target(const char *pathname)
+{
+    if (atomic_read(&hymo_atomiconfig) == 0) return NULL;
+    return __hymofs_resolve_target(pathname);
+}
+
+static inline int hymofs_reverse_lookup(const char *pathname, char *buf, size_t buflen)
+{
+    if (atomic_read(&hymo_atomiconfig) == 0) return -1;
+    return __hymofs_reverse_lookup(pathname, buf, buflen);
+}
+
+static inline bool hymofs_should_hide(const char *pathname)
+{
+    if (atomic_read(&hymo_atomiconfig) == 0) return false;
+    /* Fast path: check for NULL or empty */
+    if (!pathname || !*pathname) return false;
+    return __hymofs_should_hide(pathname, strlen(pathname));
+}
+
+static inline bool hymofs_should_spoof_mtime(const char *pathname)
+{
+    if (atomic_read(&hymo_atomiconfig) == 0) return false;
+    return __hymofs_should_spoof_mtime(pathname);
+}
+
+#else
+
+struct hymo_readdir_context {};
+static inline void hymofs_prepare_readdir(struct hymo_readdir_context *ctx, struct file *file) {}
+static inline void hymofs_cleanup_readdir(struct hymo_readdir_context *ctx) {}
+static inline bool hymofs_check_filldir(struct hymo_readdir_context *ctx, const char *name, int namlen) { return false; }
+static inline int hymofs_inject_entries(struct hymo_readdir_context *ctx, void __user **dir_ptr, int *count, loff_t *pos) { return 0; }
+static inline int hymofs_inject_entries64(struct hymo_readdir_context *ctx, void __user **dir_ptr, int *count, loff_t *pos) { return 0; }
+static inline void hymofs_spoof_stat(const struct path *path, struct kstat *stat) {}
+static inline ssize_t hymofs_filter_xattrs(struct dentry *dentry, char *klist, ssize_t len) { return len; }
+static inline bool hymofs_is_overlay_xattr(struct dentry *dentry, const char *name) { return false; }
+
+static inline struct filename *hymofs_handle_getname(struct filename *result) { return result; }
+static inline struct filename *hymofs_resolve_relative(int dfd, const char *name) { return NULL; }
+static inline char *hymofs_resolve_target(const char *pathname) { return NULL; }
+static inline char *hymofs_reverse_lookup(const char *pathname) { return NULL; }
+static inline bool hymofs_should_hide(const char *pathname) { return false; }
+static inline bool hymofs_should_spoof_mtime(const char *pathname) { return false; }
+static inline int hymofs_populate_injected_list(const char *dir_path, struct dentry *parent, struct list_head *head) { return 0; }
+static inline bool hymofs_is_inode_hidden(struct inode *inode) { return false; }
+
+#endif /* CONFIG_HYMOFS */
+
+#endif /* _LINUX_HYMOFS_H */
diff -ruN src_origin_with_susfs/fs/Kconfig src_modified_with_susfs/fs/Kconfig
--- src_origin_with_susfs/fs/Kconfig	2025-12-24 03:26:17.439900935 +0800
+++ src_modified_with_susfs/fs/Kconfig	2025-12-24 03:35:51.654032429 +0800
@@ -405,4 +405,24 @@
 config IO_WQ
 	bool
 
+config HYMOFS
+	bool "HymoFS support"
+	default n
+	help
+	  HymoFS is a kernel-level path manipulation and hiding framework.
+
+config HYMOFS_USE_KSU
+	bool "HymoFS KSU integration"
+	depends on HYMOFS
+	default n
+	help
+	  Enable KernelSU integration for HymoFS.
+
+config HYMOFS_LSMBPS
+	bool "HymoFS LSM Bypass"
+	depends on HYMOFS
+	default n
+	help
+	  Enable LSM bypass support for HymoFS.
+
 endmenu
diff -ruN src_origin_with_susfs/fs/Makefile src_modified_with_susfs/fs/Makefile
--- src_origin_with_susfs/fs/Makefile	2025-12-24 03:26:17.440041849 +0800
+++ src_modified_with_susfs/fs/Makefile	2025-12-24 03:26:17.435093504 +0800
@@ -23,6 +23,7 @@
 		kernel_read_file.o mnt_idmapping.o remap_range.o
 
 obj-$(CONFIG_KSU_SUSFS) += susfs.o
+obj-$(CONFIG_HYMOFS) += hymofs.o
 
 obj-$(CONFIG_BUFFER_HEAD)	+= buffer.o mpage.o
 obj-$(CONFIG_PROC_FS)		+= proc_namespace.o
diff -ruN src_origin_with_susfs/fs/namei.c src_modified_with_susfs/fs/namei.c
--- src_origin_with_susfs/fs/namei.c	2025-12-24 03:26:17.440091370 +0800
+++ src_modified_with_susfs/fs/namei.c	2025-12-24 03:26:17.436091363 +0800
@@ -57,6 +57,10 @@
 extern const struct qstr susfs_fake_qstr_name;
 #endif
 
+#ifdef CONFIG_HYMOFS
+#include "hymofs.h"
+#endif
+
 /* [Feb-1997 T. Schoebel-Theuer]
  * Fundamental changes in the pathname lookup mechanisms (namei)
  * were necessary because of omirr.  The reason is that omirr needs
@@ -138,8 +142,22 @@
 
 #define EMBEDDED_NAME_MAX	(PATH_MAX - offsetof(struct filename, iname))
 
+#ifdef CONFIG_HYMOFS
+struct filename *__original_getname_flags(const char __user *filename, int flags, int *empty);
+
+/* Hook getname_flags to intercept path lookups */
+struct filename *getname_flags(const char __user *filename, int flags, int *empty)
+{
+	struct filename *result = __original_getname_flags(filename, flags, empty);
+	return hymofs_handle_getname(result);
+}
+#endif
 struct filename *
+#ifdef CONFIG_HYMOFS
+__original_getname_flags(const char __user *filename, int flags, int *empty)
+#else
 getname_flags(const char __user *filename, int flags, int *empty)
+#endif
 {
 	struct filename *result;
 	char *kname;
diff -ruN src_origin_with_susfs/fs/readdir.c src_modified_with_susfs/fs/readdir.c
--- src_origin_with_susfs/fs/readdir.c	2025-12-24 03:26:17.440091370 +0800
+++ src_modified_with_susfs/fs/readdir.c	2025-12-24 03:35:51.654032429 +0800
@@ -32,6 +32,11 @@
 extern bool susfs_is_base_dentry_android_data_dir(struct dentry* base);
 extern bool susfs_is_base_dentry_sdcard_dir(struct dentry* base);
 #endif
+
+#ifdef CONFIG_HYMOFS
+#include "hymofs.h"
+#endif
+
 /*
  * Some filesystems were never converted to '->iterate_shared()'
  * and their directory iterators want the inode lock held for
@@ -180,6 +185,9 @@
 
 struct readdir_callback {
 	struct dir_context ctx;
+#ifdef CONFIG_HYMOFS
+	struct hymo_readdir_context hymo;
+#endif
 	struct old_linux_dirent __user * dirent;
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	struct super_block *sb;
@@ -267,6 +275,9 @@
 
 	if (!f.file)
 		return -EBADF;
+#ifdef CONFIG_HYMOFS
+	hymofs_prepare_readdir(&buf.hymo, f.file);
+#endif
 
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	buf.sb = f.file->f_inode->i_sb;
@@ -294,6 +305,9 @@
 	if (buf.result)
 		error = buf.result;
 
+#ifdef CONFIG_HYMOFS
+	hymofs_cleanup_readdir(&buf.hymo);
+#endif
 	fdput_pos(f);
 	return error;
 }
@@ -313,6 +327,9 @@
 
 struct getdents_callback {
 	struct dir_context ctx;
+#ifdef CONFIG_HYMOFS
+	struct hymo_readdir_context hymo;
+#endif
 	struct linux_dirent __user * current_dir;
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	struct super_block *sb;
@@ -323,6 +340,9 @@
 	int prev_reclen;
 	int count;
 	int error;
+#ifdef CONFIG_HYMOFS
+	bool buffer_full;
+#endif
 };
 
 static bool filldir(struct dir_context *ctx, const char *name, int namlen,
@@ -335,7 +355,13 @@
 	int reclen = ALIGN(offsetof(struct linux_dirent, d_name) + namlen + 2,
 		sizeof(long));
 	int prev_reclen;
+
+#ifdef CONFIG_HYMOFS
+    if (hymofs_check_filldir(&buf->hymo, name, strlen(name))) return true;
+#endif
+
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
+
 	struct inode *inode;
 #endif
 
@@ -343,8 +369,12 @@
 	if (unlikely(buf->error))
 		return false;
 	buf->error = -EINVAL;	/* only used if we fail.. */
-	if (reclen > buf->count)
+	if (reclen > buf->count) {
+#ifdef CONFIG_HYMOFS
+		buf->buffer_full = true;
+#endif
 		return false;
+	}
 	d_ino = ino;
 	if (sizeof(d_ino) < sizeof(ino) && d_ino != ino) {
 		buf->error = -EOVERFLOW;
@@ -408,6 +438,9 @@
 		.ctx.actor = filldir,
 		.count = count,
 		.current_dir = dirent
+#ifdef CONFIG_HYMOFS
+		, .buffer_full = false
+#endif
 	};
 	int error;
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
@@ -417,6 +450,20 @@
 	f = fdget_pos(fd);
 	if (!f.file)
 		return -EBADF;
+#ifdef CONFIG_HYMOFS
+	hymofs_prepare_readdir(&buf.hymo, f.file);
+	if (f.file->f_pos >= HYMO_MAGIC_POS) {
+		void __user *dir_ptr = buf.current_dir;
+		int res = hymofs_inject_entries(&buf.hymo, &dir_ptr, &buf.count, &f.file->f_pos);
+		if (res >= 0)
+			error = count - buf.count;
+		else
+			error = res;
+		hymofs_cleanup_readdir(&buf.hymo);
+		fdput_pos(f);
+		return error;
+	}
+#endif
 
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	buf.sb = f.file->f_inode->i_sb;
@@ -452,12 +499,24 @@
 		else
 			error = count - buf.count;
 	}
+#ifdef CONFIG_HYMOFS
+	if (error >= 0 && !buf.buffer_full && buf.ctx.pos < HYMO_MAGIC_POS && !signal_pending(current)) {
+		void __user *dir_ptr = buf.current_dir;
+		int res = hymofs_inject_entries(&buf.hymo, &dir_ptr, &buf.count, &f.file->f_pos);
+		if (res > 0)
+			error = count - buf.count;
+	}
+	hymofs_cleanup_readdir(&buf.hymo);
+#endif
 	fdput_pos(f);
 	return error;
 }
 
 struct getdents_callback64 {
 	struct dir_context ctx;
+#ifdef CONFIG_HYMOFS
+	struct hymo_readdir_context hymo;
+#endif
 	struct linux_dirent64 __user * current_dir;
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	struct super_block *sb;
@@ -468,6 +527,9 @@
 	int prev_reclen;
 	int count;
 	int error;
+#ifdef CONFIG_HYMOFS
+	bool buffer_full;
+#endif
 };
 
 static bool filldir64(struct dir_context *ctx, const char *name, int namlen,
@@ -479,6 +541,11 @@
 	int reclen = ALIGN(offsetof(struct linux_dirent64, d_name) + namlen + 1,
 		sizeof(u64));
 	int prev_reclen;
+
+#ifdef CONFIG_HYMOFS
+	if (hymofs_check_filldir(&buf->hymo, name, namlen)) return true;
+#endif
+
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	struct inode *inode;
 #endif
@@ -487,8 +554,12 @@
 	if (unlikely(buf->error))
 		return false;
 	buf->error = -EINVAL;	/* only used if we fail.. */
-	if (reclen > buf->count)
+	if (reclen > buf->count) {
+#ifdef CONFIG_HYMOFS
+		buf->buffer_full = true;
+#endif
 		return false;
+	}
 	prev_reclen = buf->prev_reclen;
 	if (prev_reclen && signal_pending(current))
 		return false;
@@ -548,6 +619,9 @@
 		.ctx.actor = filldir64,
 		.count = count,
 		.current_dir = dirent
+#ifdef CONFIG_HYMOFS
+		, .buffer_full = false
+#endif
 	};
 	int error;
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
@@ -558,6 +632,21 @@
 	if (!f.file)
 		return -EBADF;
 
+#ifdef CONFIG_HYMOFS
+	hymofs_prepare_readdir(&buf.hymo, f.file);
+	if (f.file->f_pos >= HYMO_MAGIC_POS) {
+		void __user *dir_ptr = buf.current_dir;
+		int res = hymofs_inject_entries64(&buf.hymo, &dir_ptr, &buf.count, &f.file->f_pos);
+		if (res >= 0)
+			error = count - buf.count;
+		else
+			error = res;
+		hymofs_cleanup_readdir(&buf.hymo);
+		fdput_pos(f);
+		return error;
+	}
+#endif
+
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	buf.sb = f.file->f_inode->i_sb;
 	inode = f.file->f_path.dentry->d_inode;
@@ -593,6 +682,15 @@
 		else
 			error = count - buf.count;
 	}
+#ifdef CONFIG_HYMOFS
+	if (error >= 0 && !buf.buffer_full && buf.ctx.pos < HYMO_MAGIC_POS && !signal_pending(current)) {
+		void __user *dir_ptr = buf.current_dir;
+		int res = hymofs_inject_entries64(&buf.hymo, &dir_ptr, &buf.count, &f.file->f_pos);
+		if (res > 0)
+			error = count - buf.count;
+	}
+	hymofs_cleanup_readdir(&buf.hymo);
+#endif
 	fdput_pos(f);
 	return error;
 }
@@ -607,6 +705,9 @@
 
 struct compat_readdir_callback {
 	struct dir_context ctx;
+#ifdef CONFIG_HYMOFS
+	struct hymo_readdir_context hymo;
+#endif
 	struct compat_old_linux_dirent __user *dirent;
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	struct super_block *sb;
@@ -696,6 +797,10 @@
 	if (!f.file)
 		return -EBADF;
 
+#ifdef CONFIG_HYMOFS
+	hymofs_prepare_readdir(&buf.hymo, f.file);
+#endif
+
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	buf.sb = f.file->f_inode->i_sb;
 	inode = f.file->f_path.dentry->d_inode;
@@ -722,6 +827,9 @@
 	if (buf.result)
 		error = buf.result;
 
+#ifdef CONFIG_HYMOFS
+	hymofs_cleanup_readdir(&buf.hymo);
+#endif
 	fdput_pos(f);
 	return error;
 }
@@ -735,6 +843,9 @@
 
 struct compat_getdents_callback {
 	struct dir_context ctx;
+#ifdef CONFIG_HYMOFS
+	struct hymo_readdir_context hymo;
+#endif
 	struct compat_linux_dirent __user *current_dir;
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	struct super_block *sb;
@@ -757,6 +868,10 @@
 	int reclen = ALIGN(offsetof(struct compat_linux_dirent, d_name) +
 		namlen + 2, sizeof(compat_long_t));
 	int prev_reclen;
+
+#ifdef CONFIG_HYMOFS
+    if (hymofs_check_filldir(&buf->hymo, name, namlen)) return true;
+#endif
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	struct inode *inode;
 #endif
@@ -838,6 +953,10 @@
 	if (!f.file)
 		return -EBADF;
 
+#ifdef CONFIG_HYMOFS
+	hymofs_prepare_readdir(&buf.hymo, f.file);
+#endif
+
 #ifdef CONFIG_KSU_SUSFS_SUS_PATH
 	buf.sb = f.file->f_inode->i_sb;
 	inode = f.file->f_path.dentry->d_inode;
@@ -872,6 +991,9 @@
 		else
 			error = count - buf.count;
 	}
+#ifdef CONFIG_HYMOFS
+	hymofs_cleanup_readdir(&buf.hymo);
+#endif
 	fdput_pos(f);
 	return error;
 }
diff -ruN src_origin_with_susfs/fs/stat.c src_modified_with_susfs/fs/stat.c
--- src_origin_with_susfs/fs/stat.c	2025-12-24 03:26:17.441091372 +0800
+++ src_modified_with_susfs/fs/stat.c	2025-12-28 11:19:46.625721984 +0800
@@ -34,6 +34,10 @@
 extern void susfs_sus_ino_for_generic_fillattr(unsigned long ino, struct kstat *stat);
 #endif
 
+#ifdef CONFIG_HYMOFS
+#include "hymofs.h"
+#endif
+
 /**
  * generic_fillattr - Fill in the basic attributes from the inode struct
  * @idmap:		idmap of the mount the inode was found from
@@ -152,12 +156,26 @@
 				  STATX_ATTR_DAX);
 
 	idmap = mnt_idmap(path->mnt);
+#ifdef CONFIG_HYMOFS
+	if (inode->i_op->getattr) {
+		int ret = inode->i_op->getattr(idmap, path, stat,
+					    request_mask,
+					    query_flags | AT_GETATTR_NOSEC);
+        if (ret == 0) hymofs_spoof_stat(path, stat);
+        return ret;
+    }
+#else
 	if (inode->i_op->getattr)
 		return inode->i_op->getattr(idmap, path, stat,
 					    request_mask,
 					    query_flags | AT_GETATTR_NOSEC);
+#endif
 
 	generic_fillattr(idmap, request_mask, inode, stat);
+#ifdef CONFIG_HYMOFS
+	/* HymoFS: Spoof timestamps if needed */
+	hymofs_spoof_stat(path, stat);
+#endif
 	return 0;
 }
 EXPORT_SYMBOL(vfs_getattr_nosec);
@@ -266,6 +284,9 @@
 	struct path path;
 	unsigned int lookup_flags = getname_statx_lookup_flags(flags);
 	int error;
+#ifdef CONFIG_HYMOFS
+	struct filename *hymo_filename = NULL;
+#endif
 
 #ifdef CONFIG_KSU_SUSFS
 	if (likely(susfs_is_current_proc_umounted()) || !ksu_su_compat_enabled) {
@@ -286,6 +307,15 @@
 
 retry:
 	error = filename_lookup(dfd, filename, lookup_flags, &path, NULL);
+	
+#ifdef CONFIG_HYMOFS
+	/* HymoFS: Handle merge directory - relative path + dirfd case */
+	if (error == -ENOENT && dfd >= 0 && filename->name[0] != '/') {
+		hymo_filename = hymofs_resolve_relative(dfd, filename->name);
+		if (hymo_filename)
+			error = filename_lookup(AT_FDCWD, hymo_filename, lookup_flags, &path, NULL);
+	}
+#endif
 	if (error)
 		goto out;
 
@@ -312,6 +342,10 @@
 		goto retry;
 	}
 out:
+#ifdef CONFIG_HYMOFS
+	if (hymo_filename)
+		putname(hymo_filename);
+#endif
 	return error;
 }
 
diff -ruN src_origin_with_susfs/fs/xattr.c src_modified_with_susfs/fs/xattr.c
--- src_origin_with_susfs/fs/xattr.c	2025-12-24 03:26:17.441091372 +0800
+++ src_modified_with_susfs/fs/xattr.c	2025-12-24 03:26:17.436091363 +0800
@@ -25,6 +25,9 @@
 #include <linux/posix_acl_xattr.h>
 
 #include <linux/uaccess.h>
+#ifdef CONFIG_HYMOFS
+#include "hymofs.h"
+#endif
 
 #include "internal.h"
 
@@ -725,6 +728,10 @@
 {
 	ssize_t error;
 	char *kname = ctx->kname->name;
+#ifdef CONFIG_HYMOFS
+	if (hymofs_is_overlay_xattr(d, kname))
+		return -ENODATA;
+#endif
 
 	if (ctx->size) {
 		if (ctx->size > XATTR_SIZE_MAX)
@@ -831,6 +838,35 @@
 	ssize_t error;
 	char *klist = NULL;
 
+#ifdef CONFIG_HYMOFS
+	size_t alloc_size = size;
+
+	if (!size) {
+		ssize_t res = vfs_listxattr(d, NULL, 0);
+		if (res <= 0)
+			return res;
+		alloc_size = res;
+	}
+
+	if (alloc_size > XATTR_LIST_MAX)
+		alloc_size = XATTR_LIST_MAX;
+
+	klist = kvmalloc(alloc_size, GFP_KERNEL);
+	if (!klist)
+		return -ENOMEM;
+
+	error = vfs_listxattr(d, klist, alloc_size);
+	if (error > 0) {
+		error = hymofs_filter_xattrs(d, klist, error);
+
+		if (size && copy_to_user(list, klist, error))
+			error = -EFAULT;
+	} else if (error == -ERANGE && size >= XATTR_LIST_MAX) {
+		/* The file system tried to returned a list bigger
+		   than XATTR_LIST_MAX bytes. Not possible. */
+		error = -E2BIG;
+	}
+#else
 	if (size) {
 		if (size > XATTR_LIST_MAX)
 			size = XATTR_LIST_MAX;
@@ -848,6 +884,7 @@
 		   than XATTR_LIST_MAX bytes. Not possible. */
 		error = -E2BIG;
 	}
+#endif
 
 	kvfree(klist);
 
diff -ruN src_origin_with_susfs/include/linux/hymo_magic.h src_modified_with_susfs/include/linux/hymo_magic.h
--- src_origin_with_susfs/include/linux/hymo_magic.h	1970-01-01 08:00:00.000000000 +0800
+++ src_modified_with_susfs/include/linux/hymo_magic.h	2025-12-28 09:31:21.902545517 +0800
@@ -0,0 +1,78 @@
+#ifndef _LINUX_HYMO_MAGIC_H
+#define _LINUX_HYMO_MAGIC_H
+
+#ifdef __KERNEL__
+#include <linux/ioctl.h>
+#include <linux/types.h>
+#include <linux/bits.h>
+#else
+#include <sys/ioctl.h>
+#include <stddef.h>
+#endif
+
+#define HYMO_MAGIC1 0x48594D4F // "HYMO"
+#define HYMO_MAGIC2 0x524F4F54 // "ROOT"
+#define HYMO_PROTOCOL_VERSION 8
+
+/*
+ * HymoFS inode marking bits (stored in inode->i_mapping->flags)
+ * Using high bits to avoid conflict with kernel AS_* flags and SUSFS bits
+ * SUSFS uses bits 33-39, we use 40+
+ */
+#ifdef __KERNEL__
+#define AS_FLAGS_HYMO_HIDE 40
+#define BIT_HYMO_HIDE BIT(40)
+/* Marks a directory as containing hidden entries (for fast filldir skip) */
+#define AS_FLAGS_HYMO_DIR_HAS_HIDDEN 41
+#define BIT_HYMO_DIR_HAS_HIDDEN BIT(41)
+#endif
+
+// Command definitions (for syscall mode - legacy)
+#define HYMO_CMD_ADD_RULE    0x48001
+#define HYMO_CMD_DEL_RULE    0x48002
+#define HYMO_CMD_HIDE_RULE   0x48003
+#define HYMO_CMD_INJECT_RULE 0x48004
+#define HYMO_CMD_CLEAR_ALL   0x48005
+#define HYMO_CMD_GET_VERSION 0x48006
+#define HYMO_CMD_LIST_RULES  0x48007
+#define HYMO_CMD_SET_DEBUG   0x48008
+#define HYMO_CMD_REORDER_MNT_ID 0x48009
+#define HYMO_CMD_SET_STEALTH 0x48010
+#define HYMO_CMD_HIDE_OVERLAY_XATTRS 0x48011
+#define HYMO_CMD_ADD_MERGE_RULE 0x48012
+#define HYMO_CMD_SET_AVC_LOG_SPOOFING 0x48013
+#define HYMO_CMD_SET_MIRROR_PATH 0x48014
+
+// Device path
+#define HYMO_DEVICE_NAME "hymo"
+#define HYMO_DEVICE_PATH "/dev/hymo"
+
+struct hymo_syscall_arg {
+    char *src;
+    char *target;
+    int type;
+};
+
+struct hymo_syscall_list_arg {
+    char *buf;
+    size_t size;
+};
+
+// ioctl definitions (for fd-based mode)
+// Must be after struct definitions
+#define HYMO_IOC_MAGIC 'H'
+#define HYMO_IOC_ADD_RULE           _IOW(HYMO_IOC_MAGIC, 1, struct hymo_syscall_arg)
+#define HYMO_IOC_DEL_RULE           _IOW(HYMO_IOC_MAGIC, 2, struct hymo_syscall_arg)
+#define HYMO_IOC_HIDE_RULE          _IOW(HYMO_IOC_MAGIC, 3, struct hymo_syscall_arg)
+#define HYMO_IOC_CLEAR_ALL          _IO(HYMO_IOC_MAGIC, 5)
+#define HYMO_IOC_GET_VERSION        _IOR(HYMO_IOC_MAGIC, 6, int)
+#define HYMO_IOC_LIST_RULES         _IOWR(HYMO_IOC_MAGIC, 7, struct hymo_syscall_list_arg)
+#define HYMO_IOC_SET_DEBUG          _IOW(HYMO_IOC_MAGIC, 8, int)
+#define HYMO_IOC_REORDER_MNT_ID     _IO(HYMO_IOC_MAGIC, 9)
+#define HYMO_IOC_SET_STEALTH        _IOW(HYMO_IOC_MAGIC, 10, int)
+#define HYMO_IOC_HIDE_OVERLAY_XATTRS _IOW(HYMO_IOC_MAGIC, 11, struct hymo_syscall_arg)
+#define HYMO_IOC_ADD_MERGE_RULE     _IOW(HYMO_IOC_MAGIC, 12, struct hymo_syscall_arg)
+#define HYMO_IOC_SET_AVC_LOG_SPOOFING _IOW(HYMO_IOC_MAGIC, 13, int)
+#define HYMO_IOC_SET_MIRROR_PATH    _IOW(HYMO_IOC_MAGIC, 14, struct hymo_syscall_arg)
+
+#endif /* _LINUX_HYMO_MAGIC_H */
\ No newline at end of file
diff -ruN src_origin_with_susfs/kernel/reboot.c src_modified_with_susfs/kernel/reboot.c
--- src_origin_with_susfs/kernel/reboot.c	2025-12-24 03:26:17.441799719 +0800
+++ src_modified_with_susfs/kernel/reboot.c	2025-12-24 03:26:17.437096872 +0800
@@ -18,6 +18,7 @@
 #include <linux/syscalls.h>
 #include <linux/syscore_ops.h>
 #include <linux/uaccess.h>
+#include <linux/hymo_magic.h>
 
 #include <trace/hooks/reboot.h>
 
@@ -29,6 +30,12 @@
 struct pid *cad_pid;
 EXPORT_SYMBOL(cad_pid);
 
+#ifdef CONFIG_HYMOFS
+/* HymoFS Hook */
+int (*hymo_dispatch_cmd_hook)(unsigned int cmd, void __user *arg) = NULL;
+EXPORT_SYMBOL(hymo_dispatch_cmd_hook);
+#endif
+
 #if defined(CONFIG_ARM)
 #define DEFAULT_REBOOT_MODE		= REBOOT_HARD
 #else
@@ -711,6 +718,13 @@
 	char buffer[256];
 	int ret = 0;
 
+#ifdef CONFIG_HYMOFS
+	/* HymoFS Hook */
+	if (magic1 == HYMO_MAGIC1 && magic2 == HYMO_MAGIC2 && hymo_dispatch_cmd_hook) {
+		return hymo_dispatch_cmd_hook(cmd, arg);
+	}
+#endif
+
 #ifdef CONFIG_KSU_SUSFS
 	ret = ksu_handle_sys_reboot(magic1, magic2, cmd, &arg);
 	if (ret) {
diff -ruN src_origin_with_susfs/security/selinux/avc.c src_modified_with_susfs/security/selinux/avc.c
--- src_origin_with_susfs/security/selinux/avc.c	2025-12-24 03:26:17.441854090 +0800
+++ src_modified_with_susfs/security/selinux/avc.c	2025-12-24 03:26:17.437465991 +0800
@@ -47,6 +47,14 @@
 #undef CREATE_TRACE_POINTS
 #include <trace/hooks/avc.h>
 
+#ifdef CONFIG_HYMOFS
+bool hymo_is_avc_log_spoofing_enabled = false;
+EXPORT_SYMBOL(hymo_is_avc_log_spoofing_enabled);
+#ifdef CONFIG_HYMOFS_USE_KSU
+extern bool susfs_is_current_ksu_domain(void);
+#endif
+#endif
+
 #ifdef CONFIG_KSU_SUSFS
 extern u32 susfs_ksu_sid;
 extern u32 susfs_priv_app_sid;
@@ -725,6 +733,17 @@
 
 	rc = security_sid_to_context(sad->tsid, &tcontext,
 				     &tcontext_len);
+#ifdef CONFIG_HYMOFS
+#ifdef CONFIG_HYMOFS_USE_KSU
+	if (unlikely(hymo_is_avc_log_spoofing_enabled && susfs_is_current_ksu_domain())) {
+		if (rc)
+			audit_log_format(ab, " tsid=%d", sad->tsid);
+		else
+			audit_log_format(ab, " tcontext=%s", "u:r:priv_app:s0:c512,c768");
+		goto hymo_bypass_orig_flow;
+	}
+#endif
+#endif
 #ifdef CONFIG_KSU_SUSFS
 	if (unlikely(sad->tsid == susfs_ksu_sid && susfs_is_avc_log_spoofing_enabled)) {
 		if (rc)
@@ -741,6 +760,11 @@
 #ifdef CONFIG_KSU_SUSFS
 bypass_orig_flow:
 #endif
+#ifdef CONFIG_HYMOFS
+#ifdef CONFIG_HYMOFS_USE_KSU
+hymo_bypass_orig_flow:
+#endif
+#endif
 	tclass = secclass_map[sad->tclass-1].name;
 	audit_log_format(ab, " tclass=%s", tclass);
 
diff -ruN src_origin_with_susfs/security/selinux/hooks.c src_modified_with_susfs/security/selinux/hooks.c
--- src_origin_with_susfs/security/selinux/hooks.c	2025-12-24 03:35:51.672032459 +0800
+++ src_modified_with_susfs/security/selinux/hooks.c	2025-12-28 10:59:51.331023702 +0800
@@ -98,6 +98,16 @@
 #include "netif.h"
 #include "netnode.h"
 #include "netport.h"
+
+#ifdef CONFIG_HYMOFS_LSMBPS
+/* HymoFS Hooks */
+int (*hymofs_selinux_bypass_file_open)(struct file *file) = NULL;
+EXPORT_SYMBOL(hymofs_selinux_bypass_file_open);
+int (*hymofs_selinux_bypass_inode_permission)(struct inode *inode) = NULL;
+EXPORT_SYMBOL(hymofs_selinux_bypass_inode_permission);
+int (*hymofs_selinux_bypass_setxattr)(struct dentry *dentry, const char *name) = NULL;
+EXPORT_SYMBOL(hymofs_selinux_bypass_setxattr);
+#endif
 #include "ibpkey.h"
 #include "xfrm.h"
 #include "netlabel.h"
@@ -3100,6 +3110,14 @@
 	if (unlikely(IS_PRIVATE(inode)))
 		return 0;
 
+#ifdef CONFIG_HYMOFS_LSMBPS
+    /* HymoFS Hook */
+    extern int (*hymofs_selinux_bypass_inode_permission)(struct inode *inode);
+    if (hymofs_selinux_bypass_inode_permission && hymofs_selinux_bypass_inode_permission(inode)) {
+        return 0;
+    }
+#endif
+
 	perms = file_mask_to_av(inode->i_mode, mask);
 
 	sid = cred_sid(cred);
@@ -3177,6 +3195,14 @@
 	u32 newsid, sid = current_sid();
 	int rc = 0;
 
+#ifdef CONFIG_HYMOFS_LSMBPS
+    /* HymoFS Hook */
+    extern int (*hymofs_selinux_bypass_setxattr)(struct dentry *dentry, const char *name);
+    if (hymofs_selinux_bypass_setxattr && hymofs_selinux_bypass_setxattr(dentry, name)) {
+        return 0;
+    }
+#endif
+
 	if (strcmp(name, XATTR_NAME_SELINUX)) {
 		rc = cap_inode_setxattr(dentry, name, value, size, flags);
 		if (rc)
@@ -3958,6 +3984,14 @@
 	struct file_security_struct *fsec;
 	struct inode_security_struct *isec;
 
+#ifdef CONFIG_HYMOFS_LSMBPS
+    /* HymoFS Hook */
+    extern int (*hymofs_selinux_bypass_file_open)(struct file *file);
+    if (hymofs_selinux_bypass_file_open && hymofs_selinux_bypass_file_open(file)) {
+        return 0;
+    }
+#endif
+
 	fsec = selinux_file(file);
 	isec = inode_security(file_inode(file));
 	/*
